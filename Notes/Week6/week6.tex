\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}
\setcounter{chapter}{5}

\begin{document}




\chapter{Abstract Representation Theory}
\section{The Center of the Group Algebra}
\begin{itemize}
    \item \marginnote{10/30:}Plan for this week.
    \begin{itemize}
        \item Today: Briefly discuss a very important concept called the \textbf{center}.
        \item Wednesday: Do algebraic numbers.
        \item Friday: Burnside's theorem.
    \end{itemize}
    \item \textbf{Center} (of a group): The set of all elements of a group $G$ that commute with every other element in $G$. \emph{Denoted by} $\bm{Z(G)}$. \emph{Given by}
    \begin{equation*}
        Z(G) = \{g\in G\mid xg=gx\ \forall\ x\in G\}
    \end{equation*}
    \begin{itemize}
        \item Note: $Z(G)$ is a subgroup of $G$.
    \end{itemize}
    \item The center is one of the most important concepts in all of representation theory.
    \begin{itemize}
        \item Example: Let $A$ be an abelian group, such as $Z(G)$. Then all its irreps are 1D.
        \begin{itemize}
            \item See Section 1.3 of \textcite{bib:FultonHarris} for an explanation.
        \end{itemize}
        \item Normally, the center of a group is too small to be interesting.
        \item However, $Z(\C[G])$ is large enough to be interesting.
    \end{itemize}
    \item \textbf{Center} (of an algebra): The set of all elements of an algebra $A$ that commute with every other element in $A$. \emph{Denoted by} $\bm{Z(A)}$. \emph{Given by}
    \begin{equation*}
        Z(A) = \{a\in A\mid xa=ax\ \forall\ x\in A\}
    \end{equation*}
    \item Proposition: If $A$ is an algebra over $\C$, $M$ is an irreducible left $A$-module, and $\rho:A\to\End(M)$ is a corresponding representation, then $x\in Z(A)$ implies that $\rho(x)=\lambda I$, i.e., $\rho(x)$ is a \emph{scalar matrix}.
    \begin{proof}
        Let $x\in Z(A)$ be arbitrary. Then for all $a\in A$, we know that $\rho(x)\rho(a)=\rho(a)\rho(x)$. Thus, $\rho(x)$ is a morphism of $A$-modules. Consequently, since $M$ is irreducible (also known as \emph{simple}), Schur's Lemma for associative algebras implies that $\Hom_A(M,M)$ is a division algebra over $\C$. But since $\C$ is the only division algebra over $\C$, we have that $\Hom_A(M,M)\cong\C$. From here, it readily follows that $\rho(x)$ is equal to some $\lambda I$.
    \end{proof}
    \item Consequence: If $M$ is reducible, we can reduce it into component scalar representations.
    \item Consequence: If $G$ is an abelian group, then every irrep $V$ is 1-dimensional.
    \begin{itemize}
        \item Additionally, $\C[G]$ is commutative and hence $\C[G]=Z(\C[G])$.
        \item Then if $V$ is an arbitrary representation of $\C[G]$ (i.e., there exists $\rho_V:\C[G]\to\End(V)$), then $V$ is equal to the direct sum of one dimensional irreducible representations. Hence, for all $g$, we have $\rho_V(g)=\lambda I$.
        \begin{itemize}
            \item Could we not have different $\lambda$'s for each irrep, i.e., $\rho_V(g)=\diag(\lambda_1,\dots,\lambda_n)$ instead of only $\rho_V(g)=\diag(\lambda,\dots,\lambda)$??
        \end{itemize}
    \end{itemize}
    \item We now try to compute $Z(\C[G])$.
    \begin{itemize}
        \item Facts:
        \begin{align*}
            Z(A_1\oplus A_2) &= Z(A_1)\oplus Z(A_2)&
            Z(M_n(\C)) &= \spn(I) \cong \C
        \end{align*}
        \item These facts coupled with the fact that $G$ is a finite group (hence $\C[G]\cong M_{n_1}(\C)\oplus\cdots\oplus M_{n_k}(\C)$ where $k$ is the number of conjugacy classes in $G$ by the example from last Wednesday's class) yield
        \begin{align*}
            Z(\C[G]) &\cong Z(M_{n_1}(\C)\oplus\cdots\oplus M_{n_k}(\C))\\
            &\cong \underbrace{\C\oplus\cdots\oplus\C}_{k\text{ times}}\\
            &= \C^k
        \end{align*}
    \end{itemize}
    \item Let $C_1,\dots,C_k$ be conjugacy classes in $G$. Then we may define
    \begin{equation*}
        e_i = \sum_{g\in C_i}g
    \end{equation*}
    for each $i=1,\dots,k$.
    \begin{itemize}
        \item Example: In $S_3$ the three $e_i$'s are $\{e,(12)+(13)+(23),(123)+(132)\}$.
    \end{itemize}
    \item We will use "$Z(G)$" to denote $Z(\C[G])$ oftentimes going forward.
    \begin{itemize}
        \item Let $x\in\C[G]$ be arbitrary. Note that $xg=gx$ for all $g\in G$ if and only if $xy=yx$ for all $y\in\C[G]$.
    \end{itemize}
    \item Claim: $Z(G)=\inp{e_1,\dots,e_k}$.
    % , that is, the $e_i$ commute with every element of $G$ expressed as $1g\in\C[G]$\footnote{In this argument, what exactly is everything?? Is $Z(G)$ the center of $G$ (as the notation would suggest) or is it $Z(\C[G])$ (as it seems to contain the elements $e_i$ of $\C[G]$)?}.
    \begin{proof}
        We will use a bidirectional inclusion proof.\par
        \underline{$\inp{e_1,\dots,e_k}\subset Z(G)$}: Let $e_i\in\C[G]$ and $x\in G$ be arbitrary. As noted above, proving that $e_ix=xe_i$ for any $x\in G$ will suffice to show that $e_ix=xe_i$ for any $x\in\C[G]$. Indeed, we do find that
        \begin{align*}
            % xe_i &= \left( \sum_{g\in G}a_gg \right)e_i\\
            % &= \left( \sum_{g\in G}a_gg \right)\left( \sum_{h\in C_i}h \right)\\
            % &= \sum_{g\in G}\left[ a_gg\left( \sum_{h\in C_i}h \right) \right]\\
            % &= \sum_{g\in G}\left[ a_g\left( \sum_{h\in C_i}gh \right) \right]\\
            % &= \sum_{g\in G}\left[ a_g\left( \sum_{h\in C_i}hg \right) \right]\\
            % &= \sum_{g\in G}\left[ a_g\left( \sum_{h\in C_i}h \right)g \right]\\
            % &= \left( \sum_{h\in C_i}h \right)\left( \sum_{g\in G}a_gg \right)\\
            % &= e_ix
            xe_ix^{-1} &= \sum_{g\in C_i}xgx^{-1} = \sum_{h\in C_i}h = e_i\\
            xe_i &= e_ix
        \end{align*}
        This naturally extends to any sums and scalar multiples of the $e_i$'s.\par
        \underline{$Z(G)\subset\inp{e_1,\dots,e_k}$}: Let $a\in Z(G)$ be arbitrary. As an element of $\C[G]$, we know that $a=\sum a_gg$ for some $a_g\in\C$. Additionally, since $a\in Z(G)$, we have that $xax^{-1}=a$ for all $x\in G$. Combining these last two results, we have that
        \begin{equation*}
            \sum_{g\in G}a_{x^{-1}gx}g = \sum_{g\in G}a_gxgx^{-1}
            = xax^{-1}
            = a
            = \sum_{g\in G}a_gg
        \end{equation*}
        Comparing like terms in the above equality, we can learn that for all $x\in G$, we have $a_{x^{-1}gx}=a_g$. In other words, all of the $a_g$'s for $g$'s in the same conjugacy class are equal. Therefore, $a$ is of the form $a=\sum_{i=1}^ka_{g_i}e_i$ for $g_i\in C_i$.
    \end{proof}
    \item Thus we get $a_ee+a_{(12)}(12)+a_{(13)}(13)+\cdots$??
    \item Computing products of the $e_i$: What if we want to compute $[(12)+(13)+(23)]^2$, for example? We have to multiply \emph{noncommutatively}, so HS formulas are out, but we can still do all nine multiplications and sum them:
    \begin{equation*}
        [(12)+(13)+(23)]^2 = 3e+3[(123)+(132)]
    \end{equation*}
    \item We now tie this claim back into our discussion of $Z(\C[G])$.
    % \item Claim: $Z(\C[G])=\inp{e_1\dots,e_k}$.
    % \begin{proof}
    %     \underline{$\inp{e_1,\dots,e_k}\subset Z(\C[G])$}: Let $e_i$ and $x=\sum_{g\in G}a_gg\in\C[G]$ be arbitrary. Then
    %     \begin{equation*}
    %         xe_i = \sum_{g\in G}a_gge_i
    %         = \sum_{g\in G}a_ge_ig
    %         = e_i\sum_{g\in G}a_gg
    %         = e_ix
    %     \end{equation*}
    %     where the second equality holds because of the claim above.\par
    %     \underline{$Z(\C[G])\subset\inp{e_1,\dots,e_k}$}: Let $a\in Z(G)$ be arbitrary. As an element of $\C[G]$, we know that $a=\sum a_gg$ for some $a_g\in\C$. Additionally, since $a\in Z(\C[G])$, we have that $xa=ax$ for all $x=\sum_{g\in G}a_gg\in\C[G]$...
    % \end{proof}
    % \begin{itemize}
    %     \item In particular, $Z(G)=\inp{e_1,\dots,e_k}$ implies that $Z(\C[G])=\inp{e_1\dots,e_k}$
    % \end{itemize}
    % \item Consider $\C[G]$.
    \begin{itemize}
        \item As we just claimed and proved, $Z(\C[G])$ has basis $e_1,\dots,e_k$.
        \item Recall that $Z(\C[G])=\C\oplus\cdots\oplus\C$, with characters $\chi_1,\dots,\chi_k$.
        \item Then $f_{\chi_i}=(0,\dots,0,1,0,\dots,0)$, where the 1 lies in the $i^\text{th}$ slot.
        \item Then we get $f_{\chi_1},\dots,f_{\chi_k}$ as a basis.
        \item It follows that $f_{\chi_i}^2=f_{\chi_i}$ and $f_{\chi_i}f_{\chi_j}=0$ for $i\neq j$; this is exactly what it means for a space to be $\C\oplus\cdots\oplus\C$.
        \item Both of these spaces (center elements and class functions) have these two interconnected bases, so the spaces are quite similar!
    \end{itemize}
    \item The center of a group algebra $Z(\C[G])$ can be identified "$=$" with the space of class functions $\C_\text{cl}(G)$ via
    \begin{equation*}
        \sum\varphi(g)g \mapsto [g\to\varphi(g)]
    \end{equation*}
    where $\varphi(xgx^{-1})=\varphi(g)$.
    \begin{itemize}
        \item This isomorphism is an isomorphism of vector spaces, \emph{not} an isomorphism of algebras.
        \begin{itemize}
            \item This is exactly the map briefly described in Lecture 3.1, down to the fact that it maps coefficients to functional outputs but allows for different kinds of multiplication!!!
        \end{itemize}
        \item However, it still has cool properties.
        \begin{itemize}
            \item For instance, consider the $\delta_{C_i}$: The functions sending $g\in C_i$ to 1 and $g\notin C_i$ to 0.
            \item The isomorphism identifies $e_i\mapsto\delta_{C_i}$.
        \end{itemize}
        \item Do we get irreducible characters (our other basis of class functions) when we sum the $\varphi(g)g$'s?
        \begin{itemize}
            \item We do! What is this??
        \end{itemize}
        \item Let's consider another basis $\chi$ of irreducibles. The basis is $f_\chi=\frac{d_\chi}{|G|}\sum_{g\in G}\chi(g^{-1})g$, and we send it to $\chi_{V^*}$.
        \item Claim:
        \begin{equation*}
            f_{\chi_i}f_{\chi_j} =
            \begin{cases}
                f_{\chi_i} & \chi_i=\chi_j\\
                0 & \chi_i\neq\chi_j
            \end{cases}
        \end{equation*}
        \begin{itemize}
            \item Things that multiply like this are called the \textbf{central idempotent}.
        \end{itemize}
        \item Thus, general multiplication works as follows.
        \begin{equation*}
            (a_1f_{\chi_1}+\cdots+a_nf_{\chi_n})(b_1f_{\chi_1}+\cdots+e_nf_{\chi_n}) = a_1b_1f_{\chi_1}+\cdots+a_nb_nf_{\chi_n}
        \end{equation*}
        \item So if we want to send $a\in Z(G)$ to $\bigoplus^k\C$, we map
        \begin{equation*}
            a=a_1f_{\chi_1}+\cdots+a_kf_{\chi_k} \mapsto (a_1,\dots,a_k)
        \end{equation*}
        \item The proof of this claim is really simple because we've already done the computation with the projector on the irrep $V_x$.
        \begin{itemize}
            \item So if you want to see $\rho(f_\chi)$, see what it does to the identity: It does $\rho(f_\chi)e=f\chi e=f_\chi$. $\rho$ is regular.
        \end{itemize}
    \end{itemize}
    \item \textbf{Central idempotent}: An element such that $a^2=a$ and $ax=xa$ for all $x\in A$.
    \item Takeaway: Class functions and the center are two approaches to the same thing.
    \begin{itemize}
        \item The great thing about the center: You can understand what it looks like because it is well-defined as a commutative algebra.
        \item If something is isomorphic to $\C\oplus\cdots\oplus\C$ as an algebra, then there is another space and basis in which your multiplication looks incredibly simple.
    \end{itemize}
    \item We might get to \textbf{Hopf algebras} at the end of the course (very interesting).
    \begin{itemize}
        \item Let $\C[G]$ be an associative algebra.
        \item Let $\C[G]^*$ be the functions on the group.
        \item Then $A\otimes A\to A$ sends $a_1\otimes a_2\mapsto a_1a_2$.
        \item When we dualize to get $A^*\otimes A^*\to A^*$, everything gets reversed, so we actually get a \textbf{comultiplication} $A\to A\otimes A$ given by $g\mapsto g\otimes g$. These two multiplications together are called a \textbf{Hopf algebra}.
        \item Knowing that there's something that we can define and understand might help us untangle the knot of all the spaces.
        \item This is pretty heavy math, though, so we won't go too deep into it if we get at all.
    \end{itemize}
    \item Today was the last associative algebra class.
    \item Going forward: Integral elements, algebraic integers, dimension of the representation divides the order or the group, Burnside's theorem.
    \item Midterm is heavily computational: Tensor products, character tables, etc. A few simple questions about things.
    \begin{itemize}
        \item Comparably less associative algebra stuff (maybe just 1 exercise).
    \end{itemize}
\end{itemize}



\section{Algebraic Numbers and the Frobenius Divisibility Theorem}
\begin{itemize}
    \item \marginnote{11/1:}Announcements.
    \begin{itemize}
        \item OH on Zoom today as well; both OH next week will be in person.
    \end{itemize}
    \item New topic for the next couple of classes (today and Friday at least, possibly Monday as well).
    \begin{itemize}
        \item Proving two wonderful theorems.
    \end{itemize}
    \item Theorem 1 (Frobenius divisibility theorem\footnote{There is no agreed-upon name for this result, but \textcite{bib:FultonHarris} call it the "Frobenius divisibility theorem."}): Let $G$ be a finite group, and let $V$ be an irreducible representation of $G$ over $\C$. Then the degree of $V$ divides the order of $G$, i.e.,
    \begin{equation*}
        d_V \mid |G|
    \end{equation*}
    \item Theorem 2 (Burnside): If $G$ is a group and $|G|=p^nq^m$, then $G$ is not simple. In fact, $G$ is \textbf{solvable}.
    \begin{itemize}
        \item Seems completely unrelated to Theorem 1, but the methods are similar.
        \item The first statement in this theorem is hard and interesting. We will briefly talk about the second one, but it follows form the first by an easy induction.
    \end{itemize}
    \item Both proofs are based on number theory.
    \begin{itemize}
        \item As a warm-up to this branch of mathematics, let's talk about the algebraic integers.
    \end{itemize}
    \item \textbf{Algebraic} (number): A number $x\in\C$ for which there exists $a_0,\dots,a_{n-1}\in\Q$ such that
    \begin{equation*}
        x^n+a_{n-1}x^{n-1}+\cdots+a_0 = 0
    \end{equation*}
    \item $\bm{\bar{\pmb{\Q}}}$: The set of all algebraic numbers.
    \begin{itemize}
        \item So $\Q\subset\bar{\Q}\subset\C$, where $\bar{\Q}$ is the set of all algebraic numbers.
        \item $\pi,\text{e}$ are famous examples of numbers that are \emph{not} algebraic.
    \end{itemize}
    \item \textbf{Algebraic} (integer): An algebraic number for which the corresponding $a_0,\dots,a_{n-1}\in\Z$.
    \item $\bm{\bar{\pmb{\Z}}}$: The set of all algebraic integers.
    \item Examples.
    \begin{enumerate}
        \item $\sqrt{2}\in\bar{\Z}$.
        \begin{itemize}
            \item Because $(\sqrt{2})^2-2=0$.
        \end{itemize}
        \item $\sqrt{3}\in\bar{\Z}$.
        \item $\sqrt{2}/2\notin\bar{\Z}$.
        \begin{itemize}
            \item Let $x=\sqrt{2}/2$.
            \item We know that $2x^2-1=0$.
            \item Suppose $d(x^n+a_{n-1}x^{n-1}+\cdots+a_0)=(2x^2-1)(dx^n+\cdots)$. This is an actual use of Gauss's Lemma from MATH 25800.
            \item So $d=1\cdot 1$, contradiction.
            \item How does this proof work??
        \end{itemize}
    \end{enumerate}
    \item To get a handle on the algebraic integers, we'll prove some basic results (Facts 1-2 below).
    \item Fact 1: For all $x\in\bar{\Q}$, there exists $d\in\N$ such that $dx\in\bar{\Z}$.
    \begin{proof}
        Take the polynomial with rational coefficients which is satisfied by $x$, and then multiply the polynomial by $d^n$ where $d=\lcm(\text{denominators of }a_0,\dots,a_{n-1})$ is the greatest common denominator of all coefficients. This yields the polynomial
        \begin{equation*}
            (dx)^n+da_{n-1}(dx)^{n-1}+\cdots+d^na_0 = 0
        \end{equation*}
        in $dx$ where each coefficient $d^ia_{n-i}$ is, by the definition of $d$, now an integer.
    \end{proof}
    \item Fact 2: $\Q\cap\bar{\Z}=\Z$.
    \begin{proof}
        We will use a bidirectional inclusion proof.\par
        \underline{$\Q\cap\bar{\Z}\subset\Z$}: Let $x\in\Q\cap\bar{\Z}$ be arbitrary. Since $x\in\Q$, there exist $a\in\Z$, $b\in\N$ with $(|a|,|b|)=1$ (that is, with $a,b$ coprime) such that $x=a/b$. Since $x\in\bar{\Z}$, there exist $a_0,\dots,a_n\in\Z$ such that
        \begin{align*}
            \left( \frac{a}{b} \right)^n+a_{n-1}\left( \frac{a}{b} \right)^{n-1}+a_{n-2}\left( \frac{a}{b} \right)^{n-2}+\cdots+a_0 &= 0\\
            a^n+a_{n-1}a^{n-1}b+a_{n-2}a^{n-2}b^2+\cdots+a_0b^n &= 0
        \end{align*}
        Now suppose for the sake of contradiction that there exists a prime number $p$ dividing $b$. Then $b=px$ for some $x\in\N$. Consequently,
        \begin{align*}
            a^n+a_{n-1}a^{n-1}px+a_{n-2}a^{n-2}(px)^2+\cdots+a_0(px)^n &= 0\\
            a^n+p(a_{n-1}a^{n-1}x+a_{n-2}a^{n-2}px^2+\cdots+a_0p^{n-1}x^n) &= 0\\
            p\underbrace{(-a_{n-1}a^{n-1}x-a_{n-2}a^{n-2}px^2-\cdots-a_0p^{n-1}x^n)}_y &= a^n
        \end{align*}
        Thus, since $a^n=py$ (where $y$ is an integer as the sum of products of integers), we have that $p\mid a^n$. It follows that $p\mid a$, since $p$ is prime and raising $a$ to a power doesn't introduce any new primes into its factorization. Consequently, since $p>1$ as a prime number, there exists a number greater than 1 dividing both $a$ and $b$. Therefore, $(|a|,|b|)>1$, a contradiction. It follows that no prime number divides $b$, and hence, we must have $b=1$ and $x=a\in\Z$, as desired.\par
        \underline{$\Z\subset\Q\cap\bar{\Z}$}: Let $x\in\Z$ be arbitrary. Then $x=x/1\in\Q$. Additionally, choosing $a_0=-x$, we have $x+a_0=0$. Thus, $x\in\bar{\Z}$. Combining these two results yields $x\in\Q\cap\bar{\Z}$, as desired.
    \end{proof}
    \item We now look at the natural problem to which an algebraic integer is always the solution.
    \item Fact 3: Let $A\in M_{n\times n}(\Z)$. If $\lambda$ is an eigenvalue of $A$, then $\lambda\in\bar{\Z}$. More simply, $Av=\lambda v$ implies that $\lambda\in\bar{\Z}$.
    \begin{proof}
        To prove that $\lambda\in\bar{\Z}$, it will suffice to find a monic polynomial $P$ with integer coefficients such that $P(\lambda)=0$. Let $\chi_A$ be the characteristic polynomial of $A$. As a characteristic polynomial, $\chi_A$ is monic. Additionally, since $A$ is a matrix over the integers, the coefficients of $\chi_A$ will all be integers. Lastly, since $Av=\lambda v$, we know that $\chi_A(\lambda)=0$.
    \end{proof}
    \item Lemma: The converse of Fact 3 is true. That is, if $\lambda\in\bar{\Z}$, then there exists $A\in M_{n\times n}(\Z)$ and $v\in\C^n$\footnote{Where does $v$ lie?? Is it $\Z^n$ or something, or are there no restrictions as I suspect?} such that $Av=\lambda v$.
    \begin{proof}
        $\lambda\in\bar{\Z}$ implies $\lambda^n+a_{n-1}\lambda^{n-1}+\cdots+a_0=0$. This implies that there exists $A\in M_{n\times n}(\Z)$ such that $\chi_A(\lambda)=\text{this polynomial}=0$.\par
        Rudenko leaves it as an exercise to find this $A$. The solution is just the Frobenius matrix from MATH 27300, i.e., if we take
        \begin{equation*}
            A =
            \begin{bmatrix}
                0 & 1 &  & \\
                 & \ddots & \ddots & \\
                 &  & 0 & 1\\
                -a_0 & -a_1 & \cdots & -a_{n-1}\\
            \end{bmatrix}
        \end{equation*}
        then $\chi_A(\lambda)=\lambda^n+a_{n-1}\lambda^{n-1}+\cdots+a_0=0$.
    \end{proof}
    \item We now use the above to give a cryptic proof of an interesting fact.
    \item Fact 4: $\bar{\Z}$ is a ring. That is, if $x,y\in\bar{\Z}$, then $x+y,xy\in\bar{\Z}$.
    \begin{proof}
        Since $x,y\in\bar{\Z}$, the lemma implies that there exist $A,B,v,w$ such that
        \begin{align*}
            Av &= xv&
            Bw &= yw
        \end{align*}
        Note that $A$ can be of dimension $n\times n$ and $B$ of dimension $m\times m$, i.e., they need not be the same dimension. Now how do we find a matrix for which the sum $x+y$ and product $xy$ are eigenvalues? We use the tensor/Kronecker product to start! In particular,
        \begin{equation*}
            (A\otimes B)(v\otimes w) = xy(v\otimes w)
        \end{equation*}
        For sum, we take $A\otimes I_m+I_n\otimes B$ so that
        \begin{equation*}
            (A\otimes I_m+I_n\otimes B)(v\otimes w) = xv\otimes w+v\otimes yw
            = (x+y)v\otimes w
        \end{equation*}
        It follows by the two lines above and Fact 3 that $xy,x+y\in\bar{\Z}$, as desired.
    \end{proof}
    \item Notes on the above proof.
    \begin{itemize}
        \item Types of proofs.
        \begin{itemize}
            \item This is a nonstandard proof from \textcite{bib:Etingof}.
            \item The old proof from the 1800s uses symmetric stuff. It goes something like this:
            \begin{itemize}
                \item Let $x=x_1,\dots,x_n$ and $y=y_1,\dots,y_m$, and take $\prod_{i,j=1}^{n,m}(t-x_i-y_j)$. Then we observe symmetric polynomials.
                \item We'll cover a lot more of this stuff later.
            \end{itemize}
            \item There is also one more (more abstract) proof using modules.
        \end{itemize}
        \item Like algebraic integers form a ring, algebraic numbers form a field.
    \end{itemize}
    \item So, cool\dots but why are algebraic integers relevant to us?
    \begin{itemize}
        \item Observe that if $G$ is a group and $\chi_V$ is a character, then for all $g\in G$, we have $\chi_V(g)\in\bar{\Z}$!
        \item Why would this be the case?
        \begin{itemize}
            \item Recall that since $g^n=e$, $\chi(g)=\tr(\rho(g))=\varepsilon_1+\cdots+\varepsilon_n$ where the $\varepsilon_i$ are $n^\text{th}$ roots of unity.
            \item Each root of unity is an algebraic integer under the polynomial $x^n-1=0$.
            \item Thus, by inducting on Fact 4, the sum $\varepsilon_1+\cdots+\varepsilon_n\in\bar{\Z}$.
        \end{itemize}
    \end{itemize}
    \item Fact 5: Let $C:=\{g_1,\dots,g_s\}$ be a conjugacy class of $G$, and let $e_C:=g_1+\cdots+g_s\in\Z[G]\subset\C[G]$. Then there exist $a_0,\dots,a_{n-1}\in\Z$ such that
    \begin{equation*}
        e_C^n+a_{n-1}e_C^{n-1}+\cdots+a_0 = 0
    \end{equation*}
    \begin{proof}
        Define $L_{e_C}:\Z[G]\to\Z[G]$ by $a\mapsto e_Ca$. Thus, $L_{e_C}$ has eigenvalue $e_C$ and matrix representation
        \begin{equation*}
            L_{e_C} =
            \begin{pNiceMatrix}[first-row,first-col]
                & g_1 & \cdots & g_n\\
                g_1\\
                \vdots\\
                g_n\\
            \end{pNiceMatrix}
            \in M_{n\times n}(\Z)
        \end{equation*}
        % So $\chi_{L_{e_C}}(L_{e_C})=0$, which implies that there exists $a_0,\dots,a_{n-1}\in\Z$ such that $L_{e_C}^n+a_{n-1}L_{e_C}^{n-1}+\cdots = 0$.
        Therefore, by an argument analogous to that used in Fact 3, the desired $a_0,\dots,a_{n-1}\in\Z$ exist.
    \end{proof}
    \item Example to illustrate the above argument: Consider $C=\{(12),(13),(23)\}\subset S_3$.
    \begin{itemize}
        \item Then $e_C=(12)+(13)+(23)$.
        \item Label the elements of $S_3$ as follows.
        \begin{equation*}
            S_3 = \{\underbrace{\vphantom{(}e}_{g_1},\underbrace{(12)}_{g_2},\underbrace{(13)}_{g_3},\underbrace{(23)}_{g_4},\underbrace{(123)}_{g_5},\underbrace{(132)}_{g_6}\}
        \end{equation*}
        \item Then the matrix of $L_{e_C}$ is given by the following.
        \begin{equation*}
            L_{e_C} =
            \begin{pNiceMatrix}[first-row,first-col]
                      & e & (12) & (13) & (23) & (123) & (132)\\
                e     & 0 & 1 & 1 & 1 & 0 & 0\\
                (12)  & 1 & 0 & 0 & 0 & 1 & 1\\
                (13)  & 1 & 0 & 0 & 0 & 1 & 1\\
                (23)  & 1 & 0 & 0 & 0 & 1 & 1\\
                (123) & 0 & 1 & 1 & 1 & 0 & 0\\
                (132) & 0 & 1 & 1 & 1 & 0 & 0\\
            \end{pNiceMatrix}
        \end{equation*}
        \begin{itemize}
            \item Notice how, for example, representing $e$ as $(1,0,0,0,0,0)$ yields
            \begin{equation*}
                L_{e_C}e = (0,1,1,1,0,0)
                = (12)+(13)+(23)
                = e_C
            \end{equation*}
            as expected.
        \end{itemize}
        \item We can then calculate that the characteristic polynomial $\chi_{L_{e_C}}$ of $L_{e_C}$ is
        \begin{equation*}
            \chi_{L_{e_C}}(\lambda) = \det(L_{e_C}-\lambda I)
            = \lambda^6-9\lambda^4
        \end{equation*}
        \item This yields
        \begin{align*}
            a_0 &= 0&
            a_1 &= 0&
            a_2 &= 0&
            a_3 &= 0&
            a_4 &= -9&
            a_5 &= 0
        \end{align*}
        as the desired coefficients.
        \item Sanity check: We can confirm that
        \begin{align*}
            e_C^6-9e_C^4 &= e_C^4(e_C^2-9)\\
            &= (9[e+(123)+(132)])(3[e+(123)+(132)]-9)\\
            &= 27[e+(123)+(132)]^2-81[e+(123)+(132)]\\
            &= 81[e+(123)+(132)]-81[e+(123)+(132)]\\
            &= 0
        \end{align*}
    \end{itemize}
    \item We will now prove Theorem 1. First, we restate it.
    \item Theorem 1 (Frobenius divisibility theorem): Let $G$ be a finite group, and let $V$ be an irreducible representation of $G$ over $\C$. Then the degree of $V$ divides the order of $G$, i.e.,
    \begin{equation*}
        d_V \mid |G|
    \end{equation*}
    \begin{proof}
        We begin with four definitions: Let $C:=\{g_1,\dots,g_s\}\subset G$ be a conjugacy class of $G$, let $\Z[G]\subset\C[G]$ be a \textbf{group ring}, let $e_C:=g_1+\cdots+g_s\in\Z[G]$, and let $\rho:G\to GL(V)$ be the group homomorphism associated with the irreducible representation $V$.\par
        With our notation set, let's look at how $\rho(g_1+\cdots+g_s)$ acts on $V$. Since $g_1+\cdots+g_s\in Z(\C[G])$, the proposition from Monday's class implies that
        \begin{equation*}
            \rho(g_1+\cdots+g_s) = \lambda I_{d_V}
        \end{equation*}
        Taking the trace of both sides of the above equation, we obtain the following. Note that in the below equations, $\chi(C)$ denotes $\chi(g_i)$ for any $g_i\in C$; all $\chi(g_i)$ are equal because $\chi$ is a class function. 
        \begin{align*}
            \tr(\rho(g_1+\cdots+g_s)) &= \tr(\lambda I_{d_V})\\
            \tr(\rho(g_1))+\cdots+\tr(\rho(g_s)) &= \lambda\tr(I_{d_V})\\
            \sum_{i=1}^s\chi(C) &= \lambda d_V\\
            |C|\chi(C) &= \lambda d_V
        \end{align*}
        It follows by a simple algebraic rearrangement that
        \begin{equation*}
            \frac{|C|\chi(C)}{d_V} = \lambda
        \end{equation*}
        We can now prove that $\lambda\in\bar{\Z}$ via Fact 4. Let $v\neq 0$. Then
        \begin{align*}
            0 &= \rho(0)v\\
            &= \rho(e_C^n+a_{n-1}e_C^{n-1}+\cdots+a_0)v\\
            &= [\rho(e_C)^n+a_{n-1}\rho(e_C)^{n-1}+\cdots+a_0]v\\
            % &= [(\lambda I)^n+a_{n-1}(\lambda I)^{n-1}+\cdots+a_0]v\\
            % &= (\lambda^n+a_{n-1}\lambda^{n-1}+\cdots+a_0)Iv\\
            &= \underbrace{(\lambda^n+a_{n-1}\lambda^{n-1}+\cdots+a_0)}_0v
        \end{align*}
        Now recall that by the first orthogonality relation, we have that
        \begin{equation*}
            \sum_C|C|\chi(C)\overline{\chi(C)} = |G|
        \end{equation*}
        % where \emph{?something?} becomes
        % \begin{equation*}
        %     \sum_{g\in G}\chi(s)\chi(\bar{s}) = |G|
        % \end{equation*}
        It follows by dividing through by $d_V$ that
        \begin{equation*}
            \frac{|G|}{d_V} = \sum_C\frac{|C|\chi(C)}{d_V}\cdot\overline{\chi(C)}
        \end{equation*}
        But $|C|\chi(C)/d_V=\lambda\in\bar{\Z}$ by the above and $\overline{\chi(C)}\in\bar{\Z}$ by the earlier note about roots of unity, so by Fact 4, the whole sum of products $|G|/d_V\in\bar{\Z}$. Naturally, $|G|/d_V\in\Q$ as well. Consequently, $|G|/d_V\in\bar{\Z}\cap\Q$, so by Fact 2, $|G|/d_V\in\Z$. Therefore, we must have $d_V\mid|G|$.
    \end{proof}
    \item Notes on the above proof.
    \begin{itemize}
        \item In this course, we will not talk to much about integral elements; those will be the focus of Rudenko's next course, Algebraic Geometry.
    \end{itemize}
    \item Definitely take some time to think through this proof before next class! It's short, but quite subtle. Next class's will be much much harder.
    \item Rudenko will not be here for next Friday's midterm; someone else will be proctoring, though.
    \item Next week's HW will be a preparational HW.
\end{itemize}



\section{Burnside's Theorem}
\begin{itemize}
    \item \marginnote{11/3:}Announcements.
    \begin{itemize}
        \item HW2 returned today; HW3 will be returned Monday.
    \end{itemize}
    \item Today: We have a masterpiece of a theorem.
    \begin{itemize}
        \item Very short, clean, powerful use of character theory.
        \item It's hard to keep the whole proof in your head.
    \end{itemize}
    \item Theorem (Burnside's theorem): If $G$ is a group and $|G|=p^aq^b$ for $p,q$ prime, then $G$ is not simple (equivalently, $G$ has no normal subgroup $N$ such that $\{e\}\trianglelefteq N\trianglelefteq G$). In fact, $G$ is solvable.
    \item \textbf{Solvable} (group): A group $G$ that has a set of subgroups $G_1,\dots,G_n$ such that\dots
    \begin{enumerate}
        \item $\{e\}\trianglelefteq G_1\trianglelefteq G_2\trianglelefteq\cdots\trianglelefteq G_n=G$;
        \item Each $G_i/G_{i-1}$ is abelian.
    \end{enumerate}
    \item Motivation for solvable groups.
    \begin{itemize}
        \item Has to do with solving equations in radicals.
        \item Equivalent to $|G|=p^aq^b$.
    \end{itemize}
    \item Before we do the proof, here's a 2-minute Galois theory sprint for a little more context on solvable groups and this theorem as a whole.
    \begin{itemize}
        \item Galois theory is something we should all learn for fun at some point; nothing is more pleasurable.
        \begin{itemize}
            \item \textcite{bib:Artin} is a very short ($<100$ pages), pleasurable introduction.
        \end{itemize}
        \item Let's formulate a result we may not know (very abstract), even if we've taken Galois theory.
        \begin{itemize}
            \item Phrasing a big part of it in just a few lines.
        \end{itemize}
        \item First, recall the algebraic numbers $\bar{\Q}$, which contain $\Q$, etc.
        \begin{itemize}
            \item Using these, we can define the \textbf{Galois group}.
            \item This group is still very difficult to get a handle on, still an active area of research under the \textbf{Langlands Program} (wherein we let $\sigma(x)=\bar{x}$??).
        \end{itemize}
        \item Now we may state the result.
        \item Theorem: $G_\Q$ acts on $\bar{\Q}$. Imagine orbits.
        \begin{itemize}
            \item Then $[\sigma(\sqrt{2})]^2=\sigma(\sqrt{2}^2)=\sigma(2)=2$.
            \item This theorem acts on orbits and tells you that orbits are in bijection with irreducible polynomials $p(x)=x^n+a_{n-1}x^{n-1}+\cdots+a_0$ over $\bar{\Q}$, i.e., all $a_i\in\Q$.
            \item Then if $\alpha\in\bar{\Q}$ implies $p_A(\alpha)=0$, $\sigma p(\alpha)=p(\sigma(\alpha))=0$.
            \item So $\sqrt{2}$ can be sent to $-\sqrt{2}$ and we can do more, too.
            \item So it's very hard to construct elements because we need to say what happens in every orbit, and we have infinitely many.
            \item What is going on here??
        \end{itemize}
        \item We won't need much of this, but it's good to talk about.
    \end{itemize}
    \item \textbf{Galois group}: The group defined as follows. \emph{Denoted by} $\bm{G_{\pmb{\Q}}}$, $\bm{\Gal(\bar{\pmb{\Q}},\pmb{\Q})}$. \emph{Given by}
    \begin{equation*}
        G_\Q = \{\sigma:\bar{\Q}\to\bar{\Q}\mid\sigma(x+y)=\sigma(x)+\sigma(y),\ \sigma(xy)=\sigma(x)\sigma(y),\ \sigma(m/n)=m/n\}
    \end{equation*}
    \begin{itemize}
        \item $\sigma$ is often thought of as a permutation.
    \end{itemize}
    \item We now start proving Burnside's theorem in steps, each of which is a theorem in its own right.
    \item Lemma 1\footnote{This is a result of number theory, not one regarding representations. But we are stating and proving it because it is foundational to our argument.}: Suppose $\varepsilon_1,\dots,\varepsilon_n$ are roots of unity such that
    \begin{equation*}
        \frac{\varepsilon_1+\cdots+\varepsilon_n}{n} \in \bar{\Z}
    \end{equation*}
    Then either $\varepsilon_1=\cdots=\varepsilon_n$ or $\varepsilon_1+\cdots+\varepsilon_n=0$.
    % \item Before we prove this lemma, we investigate why it should be true intuitively.
    % \begin{figure}[h!]
    %     \centering
    %     \begin{tikzpicture}
    %         \footnotesize
    %         \draw [-stealth] (-2.5,0) -- (2.5,0) node[right]{Re};
    %         \draw [-stealth] (0,-2.5) -- (0,2.5) node[above]{Im};
    %         \draw circle (2cm);
    
    %         \fill (2,0)  circle (1.5pt) node[below right]{1};
    %         \fill (0,0)  circle (1.5pt) node[below=2pt,fill=white,inner sep=2pt]{0};
    %         \fill (-2,0) circle (1.5pt) node[below left ]{$-1$};
    
    
    %         \draw [grx,thick,->] (0,0) -- ++(50:{2/3});
    %         \draw [grx,thick,->] (50:{2/3}) -- ++(170:{2/3});
    %         \draw [grx,thick,->] (50:{2/3}) ++(170:{2/3}) -- ++(290:{2/3});
    
    %         \foreach \x in {0,-0.5,-1,-1.5} {
    %             \draw [gry,thick,->] (\x,0) -- ++(-0.5,0);
    %         }
    
    %         \draw [rex,thick,->] (0,0) -- ++(-45:1);
    %         \draw [rex,thick,->] (-45:1) -- ++(45:1);
    %         \node [rex] at (1.4,1.4) {*};
    %         \node [rex] at (1.4,-1.47) {*};
    
    %         \draw [rey,thick,->] (0,0) -- ++(-145:0.4);
    %         \draw [rey,thick,->] (-145:0.4) -- ++(-80:0.4);
    %         \draw [rey,thick,->] (-145:0.4) ++(-80:0.4) -- ++(-110:0.4);
    %         \draw [rey,thick,->] (-145:0.4) ++(-80:0.4) ++(-110:0.4) -- ++(-170:0.4);
    %         \draw [rey,thick,->] (-145:0.4) ++(-80:0.4) ++(-110:0.4) ++(-170:0.4) -- ++(95:0.4);
    %     \end{tikzpicture}
    %     \caption{Burnside's theorem --- roots of unity lemma.}
    %     \label{fig:burnsideRootUniLemma}
    % \end{figure}
    % \begin{itemize}
    %     \item Essentially, an analogous statement to the lemma is that the sum of $n$ vectors of magnitude $1/n$ can only produce a vector of magnitude 1 if all of them are pointed in the same direction, and they can only produce a vector of magnitude 0 if they sum to zero.
    %     \begin{itemize}
    %         \item Notice how the dark green vectors sum to 0. There are three of them, so they all get scaled by $1/3$. Even though they clearly don't all correspond to third roots of unity, the fact that they reach an integer is sufficient to prove that they sum to zero.
    %         \item Notice how the light green vectors sup to $-1$. These four get scaled by $1/4$, and they all have to line up in \emph{exactly} the same direction to reach the edge of the circle.
    %         \item The red vectors, on the other hand, meander around, neither summing to zero or all pointing in the same direction. Thus, they don't hit integers.
    %     \end{itemize}
    %     \item Alternatively, we can view the point at which the $n$ vectors wind up as the center of mass thing: Notice how the dark red vectors terminate at the center of mass of the two red stars, which correspond to the full roots of unity that the scaled vectors represent.
    % \end{itemize}
    % \item We now prove the lemma.
    \begin{proof}
        Assume that it is \emph{not} true that $\varepsilon_1=\cdots=\varepsilon_n$. Then
        \begin{equation*}
            \left| \frac{\varepsilon_1+\cdots+\varepsilon_n}{n} \right| < 1
        \end{equation*}
        Define $a=a_1:=(\varepsilon_1+\cdots+\varepsilon_n)/n$. Also suppose that $a_1,\dots,a_k$ are roots of the minimal polynomial for $a$, i.e., $p(x)=(x-a_1)\cdots(x-a_k)\in\Z[X]$ is the polynomial of least degree such that $p(a)=0$; such a polynomial exists because $a$ is an algebraic integer, per the discussion of roots of unity on Wednesday.
        Now what can we say about its conjugates? Take an $a_i$. We claim that $a_i$ is also the sum of roots of unity over $n$, i.e.,
        \begin{equation*}
            a_i = \frac{\varepsilon_1^i+\cdots+\varepsilon_n^i}{n}
        \end{equation*}
        So if one coefficient is of this form, they all are! There is a proof of this that follows immediately from Galois theory via\footnote{How much do I need to know about this step?? You said there might be something about proving Burnside's theorem on the final??}
        \begin{equation*}
            \sigma\left( \frac{\varepsilon_1+\cdots+\varepsilon_n}{n} \right) = \frac{\sigma(\varepsilon_1)+\cdots+\sigma(\varepsilon_n)}{n}
        \end{equation*}
        So then since each $a_i$ satisfies $|a_i|\leq 1$ and $|a_1|<1$, we have that
        \begin{equation*}
            \left| \prod_{i=1}^na_i \right| < 1
        \end{equation*}
        So $\prod_{i=1}^na_i\in\Z$\footnote{How do we know that this is an integer??}, but since it's an integer with absolute value less than 1, it must be zero.\footnote{How does proving that the product of the $a_i$'s is zero prove that $a_1=0$??}
    \end{proof}
    \item Note: This lemma is basically just a center of mass thing, i.e., the expression $(\varepsilon_1+\cdots+\varepsilon_n)/n$ essentially gives the center of mass of the roots of unity:
    \begin{figure}[h!]
        \centering
        \begin{tikzpicture}
            \footnotesize
            \draw [-stealth] (-1.5,0) -- (1.5,0) node[right]{Re};
            \draw [-stealth] (0,-1.5) -- (0,1.5) node[above]{Im};
            \draw circle (1cm);
    
            \draw [blx,thick] ($(30:1)+(-2pt,-2pt)$) -- ++(4pt,4pt);
            \draw [blx,thick] ($(30:1)+(-2pt,2pt)$) -- ++(4pt,-4pt);
            \draw [blx,thick] ($(70:1)+(-2pt,-2pt)$) -- ++(4pt,4pt);
            \draw [blx,thick] ($(70:1)+(-2pt,2pt)$) -- ++(4pt,-4pt);
            \draw [blx,thick] ($(-20:1)+(-2pt,-2pt)$) -- ++(4pt,4pt);
            \draw [blx,thick] ($(-20:1)+(-2pt,2pt)$) -- ++(4pt,-4pt);
            \draw [blx,thick] ($(-40:1)+(-2pt,-2pt)$) -- ++(4pt,4pt);
            \draw [blx,thick] ($(-40:1)+(-2pt,2pt)$) -- ++(4pt,-4pt);
            \draw [blx,thick] ($(120:1)+(-2pt,-2pt)$) -- ++(4pt,4pt);
            \draw [blx,thick] ($(120:1)+(-2pt,2pt)$) -- ++(4pt,-4pt);
            \draw [blx,thick] ($(-140:1)+(-2pt,-2pt)$) -- ++(4pt,4pt);
            \draw [blx,thick] ($(-140:1)+(-2pt,2pt)$) -- ++(4pt,-4pt);
    
            \fill [blx] (0,0) ++(30:{1/6}) ++(70:{1/6}) ++(-20:{1/6}) ++(-40:{1/6}) ++(120:{1/6}) ++(-140:{1/6}) circle (2pt);
        \end{tikzpicture}
        \caption{Burnside's theorem --- roots of unity lemma.}
        \label{fig:burnsideRootUniLemma}
    \end{figure}
    \item Stated simply, the first Theorem (below) posits that under relevant constraints, either an element acts as a scalar \emph{or} its character is zero.
    \item Theorem 1: Let $G$ be a finite group, let $V$ be an irreducible representation of $G$, and let $C$ be a conjugacy class in $G$. Assume that $(|C|,\dim V)=1$\footnote{Both $|C|$ and $\dim V$ divide the order of the group, so they're usually not coprime, but they can be.}. Then for any $g\in C$, either $\chi_V(g)=0$ or $\rho_V(g)=\lambda I$.
    \begin{proof}
        Let $g\in C$ be arbitrary. Recall from our proof of the Frobenius divisibility theorem that
        \begin{equation*}
            \frac{|C|\chi_V(g)}{\dim V} \in \bar{\Z}
        \end{equation*}
        Recall from number theory that since $(|C|,\dim V)=1$, there exist $a,b\in\Z$ such that
        \begin{equation*}
            a|C|+b(\dim V) = 1
        \end{equation*}
        Multiplying through by $\chi_V(g)/\dim V$ reveals that
        \begin{equation*}
            \frac{\chi_V(g)}{\dim V} = \underbrace{a\vphantom{\frac{|C|\chi_V(g)}{\dim V}}}_{\in\Z\vphantom{\bar{\Z}}}\cdot\underbrace{\frac{|C|\chi_V(g)}{\dim V}}_{\in\bar{\Z}}+\underbrace{b\vphantom{\frac{|C|\chi_V(g)}{\dim V}}}_{\in\Z\vphantom{\bar{\Z}}}\cdot\underbrace{\chi_V(g)\vphantom{\frac{|C|\chi_V(g)}{\dim V}}}_{\in\bar{\Z}} \in \bar{\Z}
        \end{equation*}
        Now $\rho_V(g)$ has eigenvalues $\varepsilon_1,\dots,\varepsilon_d$ that are roots of unity. Thus, substituting into the above, we have that
        \begin{equation*}
            \frac{\varepsilon_1+\cdots+\varepsilon_d}{d} = \frac{\chi_V(g)}{\dim V}
            \in \bar{\Z}
        \end{equation*}
        Therefore, by Lemma 1, either $\chi_V(g)=\varepsilon_1+\cdots+\varepsilon_d=0$ or $\varepsilon_1=\cdots=\varepsilon_d$ so that $\rho_V(g)=\varepsilon_iI$ for any $i=1,\dots,d$, as desired.
    \end{proof}
    \item That was the hard part; it gets easier from here.
    % \item Lemma 2: Let $G$ be a finite group, let $p$ be a prime number, let $\{V:p\nmid\dim V\}$ be the set of all nontrivial irreducible representation of $G$ with dimension not divisible by $p$, and let $g\in G$ be arbitrary. Then there exists $V\in\{V:p\nmid\dim V\}$ such that $\chi_V(g)\neq 0$.
    % \begin{proof}
        
    % \end{proof}
    \item Theorem 2: Let $G$ be a finite group and let $C$ be a conjugacy class of $G$. Let $|C|=p^k$ for $k>0$. Then $G$ is not simple.
    \begin{proof}
        Since $\rho:G\to GL_d(\C)$ is a group homomorphism, $\ker(\rho)\trianglelefteq G$ is a normal subgroup of $G$. In this proof, we will construct a representation $\rho$ with nontrivial and improper kernel. Let's begin.\par
        Let $g\in C$ be arbitrary. We know that $g\nsim e$: Since $p$ is a prime number, $|C|=p^k>1$, so $C\neq\{e\}$. It follows by the second orthogonality relation that
        \begin{equation*}
            \sum_\text{irreps}\dim(V)\cdot\chi_V(g) = \sum_{V_i}\chi_{V_i}(g)\overline{\chi_{V_i}(e)}
            = 0
        \end{equation*}
        The expression on the left above is equal to
        \begin{equation*}
            \underbrace{1}_{V\text{ trivial}}+\sum_{V:p\mid\dim V}\dim(V)\cdot\chi_V(g)+\sum_{V:p\nmid\dim V}\dim(V)\cdot\chi_V(g)
        \end{equation*}
        We now take a moment to prove that there exists a $V$ such that $p\nmid\dim V$ and $\chi_V(g)\neq 0$. Suppose for the sake of contradiction that no such $V$ exists. Then by the above,
        \begin{equation*}
            1+\sum_{V:p\mid\dim V}\dim(V)\cdot\chi_V(g) = 0
        \end{equation*}
        Additionally, since $p\mid\dim(V)$ for all terms in the above sum, we can factor a $p$ out of it to get
        \begin{equation*}
            1+p\sum_{V:p\mid\dim V}\frac{1}{p}\dim(V)\cdot\chi_V(g) = 0
        \end{equation*}
        But since $(1/p)\dim(V)\cdot\chi_V(g)$ an integer implies $(1/p)\dim(V)\cdot\chi_V(g)$ an algebraic integer implies $\sum_{V:p\mid\dim V}(1/p)\dim(V)\cdot\chi_V(g)$ an algebraic integer, the above equation implies that $-1/p\in\bar{\Z}$. But since $px+1=0$ is not monic, we cannot have $-1/p\in\bar{\Z}$, and we have a contradiction.\par
        % Then there exists $V$ such that $p\nmid\dim V$, $\chi_V(g)\neq 0$. Otherwise, $0=1+p\sum\frac{\dim V}{p}\chi_V(g)-1/p\in\bar{Z}$. This gives a contradiction. Thus, we got ourselves another little theorem.
        Let's now use this $V$ such that $p\nmid\dim V$ and $\chi_V(g)\neq 0$. Since $p\nmid\dim V$, $|C|=p^k\nmid\dim V$. Thus, $(|C|,\dim V)=1$. Having proven this fact and $\chi_V(g)\neq 0$ for an \emph{arbitrary} $g\in C$, it follows by Theorem 1 that for all $a\in C$, $\rho_V(a)=\varepsilon\diag(1,\dots,1)=\varepsilon I$\footnote{How do we know it's true for all $a\in G$; couldn't they have different $\varepsilon$ or couldn't we get different $V$'s??}. Thus, if $a_1\neq a_2\in C$, $\rho_V(a_1a_2^{-1})=I$, so $a_1a_2^{-1}\in\ker(\rho_V)$, so the kernel is a normal nontrivial subgroup. The kernel is also not equal to $G$ because elements of it act trivially on $V$, a nontrivial representation, implying the existence of additional $\rho(g)$'s that act nontrivially.
    \end{proof}
    \item Takeaway: If you come up with Theorem 1, you're already almost there.
    \item We're now ready for Burnside's theorem, which we should be able to prove on our own at this point if we remember the following common trick from group theory.
    \item Theorem (Burnside's theorem): If $G$ is a group and $|G|=p^aq^b$ for $p,q$ prime, then $G$ is not simple (equivalently, $G$ has no normal subgroup $N$ such that $\{e\}\trianglelefteq N\trianglelefteq G$). In fact, $G$ is solvable.
    \begin{proof}
        Let $G$ have $|G|=p^aq^b$. Suppose for the sake of contradiction that $G$ is simple. We know that $\sum|C|=|G|$. Naturally, we may split the sum as follows.
        \begin{equation*}
            \sum_{|C|=1}|C|+\sum_{|C|>1}|C| = |G|
        \end{equation*}
        All elements in their own conjugacy class are those in the center! Thus,
        \begin{equation*}
            |Z(G)|+\sum_{|C|>1}|C| = |G|
        \end{equation*}
        But if $G$ is simple, then $Z(G)=\{e\}$. So we get
        \begin{equation*}
            1+\sum_{|C|>1}|C| = |G| = p^aq^b
        \end{equation*}
        % But since $a,b\geq 1$, dividing both sides of the above by $pq$ is not possible, so we get a contradiction.
        Additionally, recall that as a corollary to the Orbit-Stabilizer theorem, we know that $|C|\mid|G|$. Thus, in this case, $|C|=p^cq^d$ for $c\leq a$ and $d\leq b$. Moreover, by Theorem 2, $c,d\geq 1$. (If one equalled zero and the other did not, $|C|$ would be of prime power order and $G$ could not be simple, a contradiction.) Thus, the order of any conjugacy class in $G$ either equals 1 or is divisible by $pq$.\par
        It follows that the sum in the above equation is divisible by $pq$. Thus,
        \begin{equation*}
            \frac{1}{pq} = \Bigg( \underbrace{p^{a-1}q^{b-1}\vphantom{\sum_{|C|>1}}}_{\in\Z}-\underbrace{\frac{1}{pq}\sum_{|C|>1}|C|}_{\in\Z} \Bigg)
        \end{equation*}
        That is to say, $1/pq$ (which is clearly not an integer) is equal to an integer, a contradiction.
    \end{proof}
    \item We will have to prove some parts of Burnside's theorem on the final. This is important because it's so complicated with so much stuff going on that you really have to learn everything by heart before you can understand it.
    \item Midterm.
    \begin{itemize}
        \item Computation of character tables, find a character tables, compute wedge powers, tensor powers, symmetric powers, etc. Compute all this elementary stuff and then a few more complicated problems. We'll get an explicit list of topics. Construct character table for symmetries of a square, etc. Make sure you can construct the character table for $S_4$, etc. Can you sit and from scratch make a character table for $S_5$? If you can, you'll have no problem on the midterm.
    \end{itemize}
    \item Next HW is not for submission; it's just a few practice problems.
    \item Next week: Old works by Specht, which nobody thinks is useful but Rudenko. He thinks it's beautiful, though. Very 19th century feel. Then induction/restriction, and another approach using symmetric polynomials, etc.
\end{itemize}



\section{L Chapter XVIII: Representations of Finite Groups}
\emph{From \textcite{bib:Lang}.}
\setcounter{Lsection}{4}
\begin{itemize}
    \item \marginnote{11/11:}Section 4, Proposition 4.1 covers the proof of the first claim from Monday's class.
    \begin{Lproposition}\marginnote{\textup{12/26:}}
        An element of $k[G]$ commutes with every element of $G$ if and only if it is a linear combination of conjugacy classes with coefficients in $k$.
        \begin{proof}
            Let $\alpha=\sum_{\sigma\in G}a_\sigma\sigma$ and assume $\alpha\tau=\tau\alpha$ for all $\tau\in G$. Then
            \begin{equation*}
                \sum_{\sigma\in G}a_\sigma\tau\sigma\tau^{-1} = \sum_{\sigma\in G}a_\sigma\sigma
            \end{equation*}
            Hence $a_{\sigma_0}=a_\sigma$ whenever $\sigma$ is conjugate to $\sigma_0$, and this means that we can write
            \begin{equation*}
                \alpha = \sum_\gamma a_\gamma\gamma
            \end{equation*}
            where the sum is taken over all conjugacy classes $\gamma$.
        \end{proof}
    \end{Lproposition}
\end{itemize}



\section{S Chapter 6: The Group Algebra}
\emph{From \textcite{bib:Serre}.}
\begin{itemize}
    \item \marginnote{11/12:}Covers some relevant topics from this week.
    \item Section 6.5, Corollary 2 is the Frobenius divisibility theorem.
\end{itemize}



\section{E Chapter 5: Representations of Finite Groups --- Further Results}
\emph{From \textcite{bib:Etingof}.}
\begin{itemize}
    \item Section 5.3 covers Frobenius divisibility.
    \item Section 5.4 covers Burnside's theorem (very much the way we did it in class!).
\end{itemize}




\end{document}