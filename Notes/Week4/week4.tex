\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}
\setcounter{chapter}{3}

\begin{document}




\chapter{???}
\section{Representation Ring; Character Basis}
\begin{itemize}
    \item \marginnote{10/16:}Announcements.
    \begin{itemize}
        \item Reminder: Midterm 11/10.
        \item OH this week in-person at normal times.
        \item PSet 3 should be fun.
    \end{itemize}
    \item Today: Finish proving some character things.
    \item Recall: The main picture.
    \begin{itemize}
        \item Rudenko redraws Figure \ref{fig:RepTheoryStory}.
        \item We have a finite group $G$ and we are studying finite-dimensional $G$-reps over $\C$.
        \item $\C_\text{cl}[G]$ is a ring.
        \item The map\dots
        \begin{itemize}
            \item Respects addition;
            \item Sends tensor multiplication to (pointwise) functional multiplication;
            \item Sends duality to conjugation;
            \item Respects a kind of inner product, whether it be either side of $\dim_\C\Hom_G(V,W)=\inp{f_1,f_2}$.
        \end{itemize}
    \end{itemize}
    \item Today, we will see that $\C_\text{cl}[G]\cong\C^k$, where $k$ is the number of conjugacy classes.
    \begin{itemize}
        \item In other words, we will see that the number of irreps is also exactly equal to $k$, that there is a bijection $\{V_i\}\to\{\chi_i\}$, and that the $\chi_1,\dots,\chi_k$ form an orthonormal basis of $\C_\text{cl}[G]$.
    \end{itemize}
    \item Visualizing the vector space $\C_\text{cl}[G]$.
    \begin{figure}[h!]
        \centering
        \begin{tikzpicture}[scale=1.2]
            \footnotesize
            \draw [->] (-0.3,0) -- (2.4,0);
            \draw [->] (0,-0.3) -- (0,2.4);
    
            \foreach \x in {0,0.5,...,2} {
                \foreach \y in {0,0.5,...,2} {
                    \fill [bly] (\x,\y) circle (1.5pt);
                }
            }
    
            \draw [blx,ultra thick,-stealth] (0,0) -- node[black,below]{$\chi_1^{}$} (0.5,0);
            \draw [blx,ultra thick,-stealth] (0,0) -- node[black,left]{$\chi_2^{}$} (0,0.5);
        \end{tikzpicture}
        \caption{Visualizing the space of class functions on $G$.}
        \label{fig:classFuncSpace}
    \end{figure}
    \begin{itemize}
        \item It's a "cone" emanating from the origin with only lattice points.
        \begin{itemize}
            \item If $\dim\C_\text{cl}[G]=2$, the vector space consists of all the blue points in Figure \ref{fig:classFuncSpace}.
        \end{itemize}
        \item Why is it only lattice points instead of a continuous function space?
        \begin{itemize}
            \item The restrictions on coefficients are inherited from the restrictions on what kinds of spaces you can build of the form $V_1^{n_1}\oplus V_2^{n_2}$.
            \item Indeed, if it were continuous, that would imply that there is some meaning to the point $0.3\chi_1+2.5\chi_2$, i.e., there is a space $V_1^{0.3}\oplus V_2^{2.5}$. But of course, we cannot define such a space!
        \end{itemize}
        \item Why is it only \emph{nonnegative} integer coefficients and not \emph{all} integer coefficients?
        \begin{itemize}
            \item We don't have subtraction to get us to a full ring.
            \item Additionally, we can only scale and linearly combine the $\chi_i$'s with nonnegative integer coefficients because, as said above, those are the types of reducible rep decompositions we have.
        \end{itemize}
    \end{itemize}
    \item Let $[V]$ denote the \textbf{isomorphism class} of the representation $V$.
    \item \textbf{Isomorphism class} (of $V$): The set of all vector spaces $W$ that are isomorphic to $V$ as representations.
    \item This allows us to define the \textbf{representation ring}.
    \item \textbf{Representation ring} (of $G$): The ring $(R,+,\cdot)$, where $R$ is the free abelian group generated by all isomorphism classes of the representations of $G$, quotiented by the span of all linear combinations of the form $[V\oplus W]-[V]-[W]$; $+$ is well-defined via the construction of $R$, which yields $[V]+[W]=[V\oplus W]$ for all $[V],[W]$ in the ring; and $\cdot$ is defined by $[V]\cdot[W]=[V\otimes W]$. \emph{Denoted by} $\bm{R(G)}$.
    \begin{itemize}
        \item Basis: $[V_1],\dots,[V_k]$.
        \item Thus, structurally,
        \begin{equation*}
            R(G) \cong \Z^k
        \end{equation*}
        \item Elements are of the form $[V_1]+2[V_2]-3[V_3]$.
        \item Multiplication is slightly complicated because $V_i\otimes V_j=\bigoplus V_k^{n_{ijk}}$; it follows that
        \begin{equation*}
            [V_i]\cdot[V_j] = \sum n_{ijk}[V_k]
        \end{equation*}
    \end{itemize}
    \item Alternative construction of $R(G)$: Take the subring of the class ring $\C_\text{cl}[G]$ that is generated by the characters.
    \begin{itemize}
        \item To do so, define a map $R(G)\to\C^k$ where the image is linear combinations of characters $\chi_i$ with $\Z$-class.
        \item Clarify this construction??
    \end{itemize}
    \item \textbf{Virtual representation}: An element of $R(G)$.
    \begin{itemize}
        % \item We can also call elements of the group \textbf{virtual} representations; they're not, because we don't have subtraction, but we're close.
        \item We need this term because some elements of $R(G)$ --- like $-[V]$, for instance --- may not correspond to an actual representation.
        \item Indeed, note that $-[V]$ is \emph{not} $V^*$; it is just some thing that when you add it to $[V]$, you get the zero representation.
    \end{itemize}
    \item Example: Let $G=\Z/2\Z=\{e,x\}$.
    \begin{itemize}
        \item Then $R(G)=\Z^2=\Z e\oplus\Z x$ has basis $[1],[-1]$ (corresponding to the trivial and alternating representations) where we define
        \begin{align*}
            [1]^2 &= [1]&
            [1][-1] &= [-1]&
            [-1]^2 &= [1]
        \end{align*}
    \end{itemize}
    \item One reason people like this $R(G)$ is as follows.
    \begin{itemize}
        \item Initially, understanding this group is not easy because even to get started, you have to find all your characters.
        \item But, we know that
        \begin{equation*}
            R(G)\otimes_\Z\C \cong \C_\text{cl}[G]
        \end{equation*}
        \begin{itemize}
            \item So we have a ring that's hard to understand, but if we do something called an \textbf{extension of scalars} (shown above) we get an easy ring!
            \item Why?? Clarify this construction.
        \end{itemize}
        \item This is interesting because we can look at the intermediate objects. For example, could we describe $R(G)\otimes\R$ or $R(G)\otimes\Q$. Interestingly, \textbf{Artin's theorem} describes $R(G)\otimes\Q$ completely.
        \item If we try to understand $R(S_n)$, this is still hard work, but if we take $\bigoplus_{n\geq 0}R(S_n)$, we obtain an object that is remarkably, surprisingly simple. That's where we're going. This is why rep theory of finite groups is simultaneously very hard and very simple.
    \end{itemize}
    \item Lemma: Let $G$ be a finite group, let $f$ be a complex-valued\footnote{This "complex-valued" hypothesis was not stated in class, but I have to imagine it's true. Is it??} class function, and let $V$ be a $G$-rep. Then the linear map
    \begin{equation*}
        F = \sum_{g\in G}f(g)\cdot g:V\to V
    \end{equation*}
    is a morphism of $G$-representations, that is, $F\in\Hom_G(V,V)$.
    \begin{proof}
        To prove that $F\in\Hom_G(V,V)$, it will suffice to show that $xF=Fx$ for every $x\in G$. Let $x\in G$ be arbitrary. Then
        \begin{align*}
            F(xv) &= \sum_{g\in G}f(g)gxv
            \intertext{Since $\rho$ is a group homomorphism, the functions $\rho(g)\in GL(V)$ act just like the elements $g\in G$. \emph{This} is what justifies us to basically move everything around all willy-nilly. Thus, continuing from the above, we have}
            &= \sum_{g\in G}f(g)(xx^{-1})gxv\\
            &= \sum_{g\in G}f(g)x(x^{-1}gx)v\\
            \intertext{Since $x=\rho(x)$ is in the general \emph{linear} group, i.e., is a \emph{linear} map, we can factor it out of the sum of functions to get}
            &= x\left( \sum_{g\in G}f(g)x^{-1}gx \right)v\\
            \intertext{Since $f$ is a class function by hypothesis, we have $f(g)=f(x^{-1}gx)$, so}
            &= x\left( \sum_{g\in G}f(x^{-1}gx)x^{-1}gxv \right)\\
            &= x\sum_{g\in G}f(g)gv\\
            &= x(Fv)
        \end{align*}
        as desired.
    \end{proof}
    \item Recall that previously, we had $(1/|G|)\sum_{g\in G}g:V\to V^G$.
    \begin{itemize}
        \item He will put something about this being a class function on the midterm?? Review how to prove that this is a class function!
    \end{itemize}
    \item Another comment: A slightly refined question.
    \begin{itemize}
        \item Suppose you have a class function $f$ and an irrep $V$.
        \item Then we know that $F=\sum f(g)g:V\to V$ is a $G$-morphism, so it is a \textbf{homothety} by Schur's lemma.
        \item So let's find $\lambda$.
        \item Thinking a big more carefully, we know that $F$ above is
        \begin{equation*}
            \sum_{g\in G}f(g)\rho_V(g)
            = \lambda I_{d_V}
        \end{equation*}
        where $d_V$ denotes the \textbf{degree} of $V$.
        \item Now, we will compute $\lambda$ using the trace. Take the trace of both sides. Then
        \begin{align*}
            \tr(\sum_{g\in G}f(g)\rho_V(g))
            &= \tr(\lambda I_{d_V})\\
            \sum f(g)\tr(\rho_V(g)) &= \lambda d_V\\
            \sum f(g)\chi_V(g) &= \lambda d_V\\
            \lambda &= \frac{|G|}{d_V}\frac{1}{|G|}\sum_{g\in G}f(g)\overline{\chi_{V^*}(g)}\\
            &= \frac{|G|}{d_V}\inp{f,\chi_{V^*}}
        \end{align*}
    \end{itemize}
    \item \textbf{Homothety}: A map $F:V\to V$ for which there exists $\lambda\in\C$ such that $Fv=\lambda v$ for all $v\in V$.
    \begin{itemize}
        \item It just means that we're scaling.
    \end{itemize}
    \item \textbf{Degree} (of $V$): The dimension of $V$ as a vector space. \emph{Denoted by} $\bm{d_V}$. \emph{Given by}
    \begin{equation*}
        d_V = \dim V
    \end{equation*}
    \item Now, we can prove the theorem to which we've been building up the whole time.
    \item Theorem: Let $G$ be a finite group. Then the number of irreps up to isomorphism is equal to the number of conjugacy classes.
    \begin{proof}
        % Thus, since the $e_g$ are all linearly independent, demonstrating that $F(e_e)=0$ will illustrate that each $f(g)=0$. By the Lemma, $F:V_\text{reg}\to V_\text{reg}$ is a morphism of $G$-representations. Additionally, by complete reducibility, $V_\text{reg}\cong V_1^{d_{V_1}}\oplus\cdots\oplus V_s^{d_{V_s}}$. Thus, if we restrict $F$ to any irrep
        
        % It follows since $\inp{f,\chi_{V_i}}=0$ ($i=1,\dots,s$) that $\inp{f,\chi_{V_i^*}}=0$ ($i=1,\dots,s$). Consequently, by the comment above, $\sum f(g)g$ acts by zero on any irrep by the preceding lemma. Thus, since the regular representation $V_\text{reg}\cong V_1^{d_{V_1}}\oplus\cdots\oplus V_s^{d_{V_s}}$, $\sum f(g)g$ acts by zero on $V_\text{reg}$. Thus, since $\C[G]=\bigoplus_{g\in G}\C e_g$, apply $\sum f(g)g$ to $e_e$; it will go to $\sum f(g)e_g=0$ which means since each $e_g$ is linearly independent that $f=0$, a contradiction.


        Let $k$ be the number of conjugacy classes of $G$, and let $\chi_1,\dots,\chi_s$ be the characters of the irreps. By the theorem from last Wednesday's class, it follows that $\chi_1,\dots,\chi_s$ are orthonormal vectors in $\C_\text{cl}[G]$. Thus, by the corollary to the aforementioned theorem, $s\leq k$.\par
        Now, suppose for the sake of contradiction that $s<k$. Then there exists a nonzero $f\in\C_\text{cl}[G]$ such that $\inp{f,\chi_{V_i}}=0$ ($i=1,\dots,s$). By Gram-Schmidt, we can choose $f$ to be another \emph{orthonormal} vector in the list, extending it to $\chi_1,\dots,\chi_s,f$. We will now build up to proving that $f(g)=0$ for all $g\in G$ (i.e., $f=0$), which we will do by using the above lemma to construct a linear independence argument as follows. The first step is to let $V_i$ be an arbitrary irrep of $G$. Then by the above comment, $F:V_i\to V_i$ may be evaluated on any $v\in V_i$ as follows.
        \begin{equation*}
            F(v) = \lambda Iv
            = \frac{|G|}{d_{V_i}}\inp{f,\chi_{V_i^*}}\cdot v
            = \frac{|G|}{d_{V_i}}\overline{\inp{f,\chi_{V_i}}}\cdot v
            = \frac{|G|}{d_{V_i}}\overline{0}\cdot v
            = 0
        \end{equation*}
        It follows that $F=0$ on \emph{any} representation since by complete reducibility, they're all direct sums of irreps. In particular, $F:V_\text{reg}\to V_\text{reg}$ is the zero operator, where $V_\text{reg}\cong V_1^{d_{V_1}}\oplus\cdots\oplus V_s^{d_{V_s}}$ is the regular representation. Thus, for example, $F(e_e)=0$. But we also know that
        \begin{equation*}
            F(e_e) = \sum_{g\in G}f(g)\cdot ge_e
            = \sum_{g\in G}f(g)\cdot e_g
        \end{equation*}
        Consequently, by transitivity, we have that
        \begin{equation*}
            0 = \sum_{g\in G}f(g)\cdot e_g
        \end{equation*}
        But since the $e_g$ are all linearly independent by the definition of the regular representation, we have that each $f(g)=0$, as desired. This means that $f=0$, contradicting our original supposition.
    \end{proof}
    \item That is the end of this story.
    \item Here's one consequence of the above theorem.
    \begin{itemize}
        \item We now know that the space of class functions has an orthonormal basis $\chi_{V_1^*},\dots,\chi_{V_k^*}$.
        \item If we denote the conjugacy classes of $G$ by $C_1,\dots,C_k$, then another obvious basis of $\C_\text{cl}[G]$ is $\delta_{C_1},\dots,\delta_{C_k}$ defined by
        \begin{equation*}
            \delta_{C_i}(g) =
            \begin{cases}
                1 & g\in C_i\\
                0 & g\notin C_i
            \end{cases}
        \end{equation*}
        \item This new basis is orthogonal: We have
        \begin{equation*}
            \inp{\delta_{C_i},\delta_{C_j}} = \frac{1}{|G|}\sum_{g\in G}\delta_{C_i}(g)\delta_{C_j}(g) =
            \begin{cases}
                0 & i\neq j\\
                \frac{|C_i|}{|G|} & i=j
            \end{cases}
        \end{equation*}
        \begin{itemize}
            \item Justifying this computation: If $i\neq j$, then at least one of $\delta_{C_i},\delta_{C_j}$ will be zero; if $i=j$, then they're both nonzero and equal to 1 for all $|C_i|$ elements $g\in C_i$.
        \end{itemize}
        \item What is the change of basis matrix between $\{\delta_{C_i}\}$ and $\{\chi_{V_i^*}\}$? It's the character table.
        \begin{itemize}
            \item The orthogonality condition for characters then just comes from the fact that we're going from one orthogonal basis to another.
            \item What are the exact bases we change between??
        \end{itemize}
    \end{itemize}
\end{itemize}



\section{Office Hours}
\begin{itemize}
    \item \marginnote{10/17:}\textbf{Transitive} (group action): A group action for which the \textbf{orbit} of $x$ is equal to $X$ for any $x\in X$.
    \item \textbf{Orbit} (of $x\in X$): The set of $g\cdot x$ for all $g\in G$.
    \item \textbf{Diagonal action} (of $G$ on $X\times X$): The action defined as follows. \emph{Given by}
    \begin{equation*}
        g\cdot(x_1,x_2) = (g\cdot x_1,g\cdot x_2)
    \end{equation*}
    \item Check \textcite{bib:Etingof} for some things??
\end{itemize}




\end{document}