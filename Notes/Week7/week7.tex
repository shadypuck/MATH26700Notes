\documentclass[../notes.tex]{subfiles}

\pagestyle{main}
\renewcommand{\chaptermark}[1]{\markboth{\chaptername\ \thechapter\ (#1)}{}}
\setcounter{chapter}{6}

\begin{document}




\chapter{Representations of the Symmetric Group}
\section{Specht Modules}
\begin{itemize}
    \item \marginnote{11/6:}Announcements.
    \begin{itemize}
        \item Midterm description is on the Canvas page.
        \item Review what he says to review, and then look at the PSets. The operator averaging stuff and $S_4$, $S_5$ examples are most important.
        \item New HW will be due next Friday (not this Friday).
    \end{itemize}
    \item New topic: Representations of $S_n$.
    \begin{itemize}
        \item We will talk about these almost until the end of the course.
        \item Very hard.
        \item Any specialist in rep theory will still say that they know some approaches, but nobody understands this stuff completely.
        \item We'll explore some phenomena, but if we feel after this course that we still don't understand everything about $S_n$, that's typical; if we think we understand everything, we're probably wrong.
    \end{itemize}
    \item Representation theory of $GL_n(\F_{p^k})$ is related but even worse.
    \begin{itemize}
        \item Same with $O_n(\F_{p^k})$.
        \item Recently, all this stuff was understood with something called linquistic (??) theory, but that's far beyond us.
    \end{itemize}
    \item $|S_n|=n!$, and the conjugacy classes are in bijection with cyclic structures of a permutation.
    \begin{itemize}
        \item Our good understanding of the conjugacy classes of $S_n$ is the only thing that makes this problem the slightest bit tractable.
        \item Cyclic structures are also in bijection with the \textbf{partitions} of a number; recall that we briefly talked about these in MATH 25700!
    \end{itemize}
    \item \textbf{Partition} (of $n\in\N$): An ordered tuple satisfying the following constraints. \emph{Denoted by} $\bm{\lambda}$, $\bm{(\lambda_1,\ldots,\lambda_k)}$. \emph{Constraints}
    \begin{enumerate}
        \item $\lambda_i\in\N$ for $i=1,\dots,k$;
        \item $\lambda_1\geq\cdots\geq\lambda_k$;
        \item $\lambda_1+\cdots+\lambda_k=n$.
    \end{enumerate}
    \item Example: The partitions of the number "4" are $(4)$, $(3,1)$, $(2,2)$, $(2,1,1)$, and $(1,1,1,1)$.
    \begin{itemize}
        \item This is the same way we've been denoting representations!
    \end{itemize}
    \item $\bm{p(n)}$: The number of possible partitions of $n$.
    \begin{itemize}
        \item Hardy and Ramanujan helped understand the number $p(n)$ of partitions of $n$, but they're still very hard to understand.
    \end{itemize}
    \item One way to understand $p(n)$ is through its encoding in the \textbf{generating function}
    \begin{equation*}
        \sum_{n\geq 1}p(n)x^n = 1+x+2x^2+3x^3+5x^4+\cdots
    \end{equation*}
    \begin{itemize}
        \item We can think of the above generating function as an actual function of $x$ if it converges for small $x$; of it doesn't converge, then we just think of it as a "meaningless" \textbf{formal power series}.
        \item To choose a partition, we need to choose a certain number of 1's, a certain number of 2's, a certain number of 3's, etc. all the way up to $n$.
        \item So let's look at
        \begin{equation*}
            (1+x+x^2+\cdots)(1+x^2+x^4+\cdots)(1+x^3+x^6+\cdots)(1+x^4+x^8+\cdots)\cdots
        \end{equation*}
        \begin{itemize}
            \item Formally, this is
            \begin{equation*}
                \prod_{i=1}^\infty\left( \sum_{j=0}^\infty x^{ij} \right)
            \end{equation*}
            \item This equals the generating function! It tells us that to compute $p(100)x^{100}$, we need only look at certain terms.
        \end{itemize}
        \item Recall that we can write $1+x+x^2+\cdots=1/(1-x)$. Doing similarly for other terms transforms the above product into
        \begin{equation*}
            \frac{1}{1-x}\frac{1}{1-x^2}\frac{1}{1-x^3}\cdots
        \end{equation*}
    \end{itemize}
    \item \textbf{Generating function}: An encoding of an infinite sequence of numbers as the coefficients of a formal power series.
    \item \textbf{Formal power series}: An infinite sum of terms of the form $ax^n$ that is considered independently from any notion of convergence.
    \item The above discussion of $p(n)$ as a generating function is only for our fun; Rudenko is not going to use this in any way.
    \begin{itemize}
        \item It's just a pretty function.
        \item Takeaway: We can write the generating function as something nice and then use it to prove something.
    \end{itemize}
    \item We can visualize these partitions using something called a \textbf{Young diagram}.
    \begin{figure}[h!]
        \centering
        \begin{subfigure}[b]{0.3\linewidth}
            \centering
            \ydiagram{5,4,4,3,2,1,1}
            \caption{$\lambda=(5,4,4,3,2,1,1)$.}
            \label{fig:youngDiagram20a}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\linewidth}
            \centering
            \ydiagram{7,5,4,3,1}
            \caption{$\lambda'=(7,5,4,3,1)$.}
            \label{fig:youngDiagram20b}
        \end{subfigure}
        \caption{Young diagrams for a partition of 20.}
        \label{fig:youngDiagram20}
    \end{figure}
    \begin{itemize}
        \item Suppose we have the following partition of 20: $(5,4,4,3,2,1,1)$.
        \item Then we draw 5 cages for 5 little birds, followed by 4 cages for 4 little birds, etc.
        \item Thus, the $i^\text{th}$ row of boxes has length $\lambda_i$.
        \item The same way you can denote by $\lambda$ the whole \emph{partition}, you can denote by $\lambda$ the whole \emph{diagram}.
        \item This is just a way to visualize partitions.
        \item Recall the three partitions of $S_3$, corresponding to its representations: $(3)$, $(2,1)$, $(1,1,1)$.
        \item Moreover, these diagrams are actually meaningful!
    \end{itemize}
    \item \textbf{Inverse} (of $\lambda$): The partition $(\lambda_1',\dots,\lambda_k')$ defined as follows. \emph{Denoted by} $\bm{\lambda'}$. \emph{Given by}
    \begin{equation*}
        \lambda_i' = |\{\lambda_j\mid\lambda_j>i\}|
    \end{equation*}
    for all $i=1,\dots,k$.
    \begin{itemize}
        \item We can see that $\lambda_1'\geq\cdots\geq\lambda_k'$.
        \item We can also see that the sum will still be $n$.
        \item Moreover, if we do this twice, we'll get back to $\lambda$, i.e., $(\lambda')'=\lambda$.
        \item We can prove $(\lambda')'=\lambda$ combinatorially, too, (that is, without Young diagrams) but that gets pretty complicated.
    \end{itemize}
    \item Example: If $\lambda=(5,4,4,3,2,1,1)$ as above, then $\lambda'=(7,5,4,3,1)$.
    \begin{itemize}
        \item See Figure \ref{fig:youngDiagram20b}.
        \item Moreover, the Young diagrams are related by a flip akin to matrix transposition.
        \item Notice how the definition of inversion \emph{exactly} specifies this flip in the picture: The number of $\lambda_j$'s that have length at least 1 is all the first column of Figure \ref{fig:youngDiagram20a}, the number of length at least 2 is all the second column, etc.
    \end{itemize}
    \item Onto the next question, which is the main miracle.
    \begin{itemize}
        \item Main miracle: There exists a natural (i.e., canonical) bijection between the conjugacy classes and irreducible representations of $S_n$.
        \item We've explored a duality for general finite groups $G$, before, but never a bijection.
        \begin{itemize}
            \item In $S_n$, there \emph{is} this natural bijection.
            \item If you understand why intuitively, you will have started to understand the representation theory of $S_n$.
        \end{itemize}
    \end{itemize}
    \item If we define $\lambda\mapsto n$ (??), then there is some irrep $V_\lambda$ corresponding to $\lambda$. We will look at the \textbf{Specht module} construction of $V_\lambda$.
    \begin{itemize}
        \item Some of the proofs Rudenko will present, he stole from \textcite{bib:Etingof}, and some of the proofs he invented himself.
        \item This is \emph{by far} the best construction, even though it's exceedingly rare in the literature.
    \end{itemize}
    \item The usual construction.
    \begin{itemize}
        \item Take $\C[S_n]$ with coefficients $a_\lambda,b_\lambda$, etc. similar over conjugacy classes and do something with it??
        \item "Just say NO!" to this construction.
    \end{itemize}
    \item Here is the better idea.
    \begin{itemize}
        \item Consider an algebra of polynomials with rational coefficients: $\Q[x_1,\dots,x_n]$.
        \begin{itemize}
            \item We could also do real or complex, but rational is nice.
        \end{itemize}
        \item For symmetric groups, all representations will be integers, etc.??
        \item One thing to emphasize about this algebra: It is a \textbf{graded} algebra.
        \begin{itemize}
            \item If represented by $A$, then it equals $A_0\oplus A_1\oplus A_2\oplus\cdots$ where
            \begin{equation*}
                A_m = \left\{ \sum_{k_1+\cdots+k_n=m}a_{k_1\cdots k_n}x_1^{k_1}\cdots x_n^{k_n} \right\}
            \end{equation*}
            \begin{itemize}
                \item I.e., $A_m$ is the sum of all polynomials with degree equal to $m$.
                \item Example: If we take $1+x_1^2x_2^3+x_1x_2+x_1^{100}+x_1x_2^{99}$, we can then break this polynomial up into polynomials of degree 1, 5, 2, and 100.
            \end{itemize}
            \item We also have $A_{m_1}\cdot A_{m_2}\subset A_{m_1+m_2}$.
            \begin{itemize}
                \item Exmaple: $x_1x_2^2\cdot(x_1+x_2)=x_1^2x_2^2+x_1x_2^3$.
            \end{itemize}
        \end{itemize}
        \item With this algebra in hand, we may let $S_n\acts\Q[x_1,\dots,x_n]$ via
        \begin{equation*}
            \sigma P(x_1,\dots,x_n) = P(x_{\sigma_{-1}(1)},\dots,x_{\sigma^{-1}(n)})
        \end{equation*}
        \begin{itemize}
            \item In other words, $\sigma$ is transposing polynomials.
            \item Example: $(12)(x_1^2+x_2^3+x_3)=x_2^2+x_1^3+x_3$.
        \end{itemize}
        \item Thus, we call as $A_1$ the representation $V_\text{perm}^*$.
        \begin{itemize}
            \item This is because $A_1=\spn(x_1+\cdots+x_n)$, and permuting these is much like permuting the basis of a vector space, as the typical permutation representation does.
            \item It could technically be the isomorphic representation $V_\text{perm}$, but the dual fits better here for reasons??
        \end{itemize}
        \item Then $A_2=S^2V^*$.
        \begin{itemize}
            \item So if $A_1$ had basis $e^1,\dots,e^m$, $A_2$ has basis $e^ie^j$.
            \item Why are we choosing these sets??
        \end{itemize}
        \item Continuing, $A_3=S^3V^*$.
        \item It follows that the representation of the overall thing is
        \begin{equation*}
            \bigoplus_{m\geq 0}(S^mV_\text{perm}^*)
        \end{equation*}
        \begin{itemize}
            \item This is called the \textbf{symmetric algebra}.
        \end{itemize}
    \end{itemize}
    \item \textbf{Graded} (algebra): An algebra for which the underlying additive group is a direct sum of abelian groups $A_i$ such that $A_iA_j\subset A_{i+j}$.
    \item So how do we construct representations?
    \begin{itemize}
        \item For $S_2$, $x_1-x_2$ changes sign when we apply $S_2$.
        \item For $S_3$\dots
        \begin{itemize}
            \item The trivial's polynomial is 1 and \emph{tableaux}.
            \item The standard is $(2,1)$. When we apply $S_3$ to $(x_1-x_2)$, we get
            \begin{equation*}
                \langle (x_1-x_2),(x_2-x_1),(x_1-x_3),(x_3-x_1),(x_2-x_3),(x_3-x_2) \rangle
            \end{equation*}
            \begin{itemize}
                \item If we let $a=x_1-x_2$, $b=x_2-x_3$, then some elements equal $a+b$. This is another way to think about the action.
            \end{itemize}
            \item What about the alternating representation? We have $(x_1-x_2)(x_2-x_3)(x_1-x_3)=\Delta_{123}$, which changes sign when we apply any element with sign $-1$!
        \end{itemize}
        \item For $S_4$\dots
        \begin{itemize}
            \item $(4)$ is 1.
            \item $(3,1)$ is $S_4(x_1-x_2)=\Delta_{12}$.
            \item $(1,1,1,1)$ is $(x_1-x_2)(x_1-x_3)(x_1-x_4)(x_2-x_3)(x_2-x_4)(x_3-x_4)=\Delta_{1234}$.
            \item $(2,1,1)$ is $(x_1-x_2)(x_1-x_3)(x_2-x_3)$.
            \begin{itemize}
                \item We got this polynomial by guessing; the same way $(x_1-x_2)$ worked in multiple cases, maybe this one does too! And it does.
                \item Something to check is that $\Delta_{123}-\Delta_{124}-\Delta_{134}-\Delta_{234}=0$.
            \end{itemize}
            \item $(2,2)$ is $(x_1-x_2)(x_3-x_4)$.
            \begin{itemize}
                \item Something related we can prove is that
                \begin{equation*}
                    (x_1-x_2)(x_3-x_4)-(x_1-x_3)(x_2-x_4)-(x_1-x_4)(x_2-x_3) = 0
                \end{equation*}
                \item This formula appears in \textbf{cross ratios}, which we can discuss in Rudenko's algebraic geometry course next quarter.
            \end{itemize}
            \item For $\lambda=(4,3,1)$, we have $\Delta_{123}\Delta_{45}\Delta_{67}$, and we act by $S_8$ upon this! Explicitly, we have $S_8(x_1-x_2)(x_1-x_3)(x_2-x_3)(x-4-x_5)(x_6-x_7)$.
            \item Takeaway: It all depends on column length!
        \end{itemize}
        \item These polynomials are called \textbf{Vandermonde determinants}; those are the little $\Delta$ things with subscripts. We'll talk about these next times.
    \end{itemize}
    \item We need to prove reducibility and not pairwise isomorphic to make sure that this construction is valid, but that's easy!
\end{itemize}



\section{Vandermonde Determinants}
\begin{itemize}
    \item \marginnote{11/8:}Announcements.
    \begin{itemize}
        \item OH tonight at 6:00 PM.
    \end{itemize}
    \item Consider $S_n$.
    \begin{itemize}
        \item Recall the symmetric algebra $R=\Q[x_1,\dots,x_n]$, which is a graded ring $\bigoplus_{d>0}R_d$ where $R_d=S^dV_\text{perm}^*$.
        \item The action of $S_n\acts\Q[x_1,\dots,x_n]$ is $\sigma P(x_1,\dots,x_n)=P(x_{\sigma^{-1}(1)},\dots,x_{\sigma^{-1}(n)})$.
    \end{itemize}
    \item With the definitions of last class behind us, we can now look at the \textbf{space of invariants} $R^{S_n}$, isotypical components of which $\sigma$ acts on trivially.
    \begin{equation*}
        R^{S_n} := \{P(x_1,\dots,x_n)\mid\forall\ \sigma\in S_n,\ P(x_{\sigma(1)},\dots,x_{\sigma(n)})=P(x_1,\dots,x_n)\}
    \end{equation*}
    \begin{itemize}
        \item This is the ring of symmetric polynomials.
        \item Example: If $n=3$, then $x_1^3+x_2^3+x_3^3-3x_1x_2x_3\in\Z^{S_3}$.
    \end{itemize}
    \item We now define some stuff to help us prove a major result: The $n$ elementary symmetric polynomials.
    \begin{itemize}
        \item $\sigma_1=x_1+\cdots+x_n=\sum_{1\leq i\leq n}x_i$.
        \item $\sigma_2=x_1x_2+\cdots+x_1x_n+x_2x_3+\cdots=\sum_{1\leq i<j\leq n}x_ix_j$.
        \item $\sigma_k=\sum_{1\leq i_1<\cdots<i_k\leq n}x_{i_1}\cdots x_{i_k}$.
        \item $\sigma_n=x_1\cdots x_n$.
    \end{itemize}
    \item With these definitions, we can say that
    \begin{equation*}
        x^n+a_{n-1}x^{n-1}+\cdots+a_0 = (x-x_1)\cdots(x-x_n)
    \end{equation*}
    where
    \begin{align*}
        a_{n-1} &= -\sigma_1&
        a_{n-2} &= \sigma_2&
        &\dots&
        a_0 &= (-1)^n\sigma_n
    \end{align*}
    \item Fundamental theorem.
    \begin{itemize}
        \item Basic statement: Every polynomial is a polynomial in these polynomials.
        \item A more precise statement follows.
    \end{itemize}
    \item Theorem (Fundamental theorem of symmetric polynomials): We have that
    \begin{equation*}
        \Q[x_1,\dots,x_n]^{S_n} = \Q[\sigma_1,\dots,\sigma_n]
    \end{equation*}
    \item Before we prove the fundamental theorem, there are a few points we need to discuss.
    \item Example:
    \begin{itemize}
        \item Take $x^2+px+q=0$.
        \item If it has two roots $x_1,x_2$, then $\sigma_1=x_1+x_2=-p$ and $\sigma_2=x_1x_2=q$.
        \item Then $x_1^2+x_2^2=\sigma_1^2-2\sigma_2^2=p^2-2q$.
        \item Thus, if we take $(x_1-x_2)^2=(x_1+x_2)^2-4x_1x_2=\sigma_1^2-4\sigma_2=p^2-4q$, which is the discriminant.
        \item In general, $x_1^n+x_2^n$ has an expression as a polynomial in $\sigma_1,\sigma_2$. This will be a homework problem.
        \item What is going on here?? Is $x^2+px+q$ even in $\Q[x]^{S_n}$? If so, why do we factor it into $\sigma_1,\sigma_2$ instead of just $\sigma$? What are the other examples about?
    \end{itemize}
    \item \textbf{Lexicographic order} (on monomials): An ordering of monomials based on the following rule. \emph{Denoted by} $\bm{\succ}$. \emph{Given by}\par
    $x_1^{a_1}\cdots x_n^{a_n}\succ x_1^{b_1}\cdots x_n^{b_n}$\dots
    \begin{enumerate}
        \item If $a_1>b_1$ OR\dots
        \item If $a_1=b_1$ and $a_2>b_2$ OR\dots
        \item $a_1=b_1$ and $a_2=b_2$ and $a_3>b_3$ OR\dots
        \item So on and so forth.
    \end{enumerate}
    \item Notes on the lexicographic ordering.
    \begin{itemize}
        \item Don't think of this order like an ordering on integers.
        \item This allows us to define the key notion for a number of proofs we'll see in the coming days.
        \item Although it may seem counterintuitive, the lexicographic ordering is still determined for polynomials such as $\sigma_1$. For example, we may look at
        \begin{equation*}
            \sigma_1 = x_1+\cdots+x_n
        \end{equation*}
        and think, "Wait a second --- all these terms have the same order: They all have the same exponent of 1." However, we would be discounting the fact that the lexicographic ordering views $\sigma_1$ as
        \begin{equation*}
            \sigma_1 = x_1^1x_2^0\cdots x_n^0+\cdots+x_1^0\cdots x_{n-1}^0x_n^1
        \end{equation*}
        From here, we can see that $LM(\sigma_1)=x_1^1x_2^0\cdots x_n^0=x_1$.
    \end{itemize}
    \item \textbf{Largest monomial} (of $P\neq 0$); The monomial in $P(x_1,\dots,x_n)\neq 0$ that is the largest lexicographically. \emph{Denoted by} $\bm{LM(P)}$.
    \item $\bm{C_{LM}(P)}$: The coefficient of $LM(P)$.
    \item Example: Consider the polynomial $P=x_1^2+x_1^3x_2x_3-7x_1^3x_2x_3^{100}$.
    \begin{itemize}
        \item Then $LM(P)=x_1^3x_2x_3^{100}$ and $C_{LM}(P)=-7$.
    \end{itemize}
    \item Properties.
    \begin{enumerate}
        \item $P,Q\neq 0$ implies that $LM(PQ)=LM(P)LM(Q)$.
        \begin{itemize}
            \item Using inductive reasoning, try multiplying the example above by $Q=x_1^2+x_2^2+x_3^2$!
            \item Rudenko will not give rigorous proofs of any of these properties; they will just confuse us. It's better to do everything intuitively here.
        \end{itemize}
    \end{enumerate}
    \item Lemma: If $P\in\Q[x_1,\dots,x_n]^{S_n}$ and $LM(P)=x_1^{a_1}\cdots x_n^{a_n}$, then $a_1\geq\cdots\geq a_n$.
    \begin{proof}
        Let $i<j$. Suppose for the sake of contradiction that $a_j>a_i$. Let $\sigma=(ij)\in S_n$. Since $P$ is symmetric, $\sigma P=P$. But then in particular, the monomial $\sigma LM(P)$ in $P$ is lexicographically larger than $LM(P)$. Thus, $LM(P)$ is not the lexicographically largest monomial in $P$, a contradiction.\par
        Here's a simple example to illustrate the idea behind this proof: Let $P=x^2y+xy^2\in\Q[x,y]^{S_n}$. Suppose we pick $LM(P)=xy^2$ (obviously this is the wrong choice, but that's the contradiction we'll see). We observe that $2=a_2>a_1=1$ in this case. Let $\sigma=(12)$. Then $\sigma LM(P)=yx^2=x^2y\succ xy^2=LM(P)$. So $\sigma LM(P)\succ LM(P)$. Thus, $LM(P)$ is not the lexicographically largest monomial in $P$, and we have \emph{formally} proven that our initial choice of $LM(P)$ was incorrect.
    \end{proof}
    \item We now have everything we need to prove the fundamental theorem. As such, we will restate and prove it.
    \item Theorem (Fundamental theorem of symmetric polynomials): We have that
    \begin{equation*}
        \Q[x_1,\dots,x_n]^{S_n} = \Q[\sigma_1,\dots,\sigma_n]
    \end{equation*}
    \begin{proof}
        % Claim: Any symmetric polynomial can be expressed via $\sigma_1,\dots,\sigma_n$.
        % Suppose not. Take a counterexample of the smallest degree and among them, the choice with the smallest $LM$. The set of degrees is a set of numbers, which must have a smallest element.
        % Example: Let $P(x_1,\dots,x_n)=C_{LM}(P)LM(P)+\text{smaller monomials}$. We know that $P$ is symmetric. Thus, we claim that $a_1\geq\cdots\geq a_n$ (Imagine they don't; then we can exchange something and get a lexicographically larger monomial).
        % We want to show that $LM(\sigma_1)=x_1$, $LM(\sigma_2)=x_1x_2$, \dots, $LM(\sigma_n)=x_1\cdots x_n$. Consider $\sigma_n^{a_n}$. This clearly divides $LM(P)$ since $a_n$ is minimal. Now multiply by $\sigma_{n-1}^{a_{n-1}-a_n}$. Continuing on, we get
        % \begin{equation*}
        %     \sigma_n^{a_n}\sigma_{n-1}^{a_{n-1}-a_n}\sigma_{n-2}^{a_{n-2}-a_{n-1}}\cdots\sigma_1^{a_1-a_2} =: Q
        % \end{equation*}
        % Thus, $LM(P)=LM(Q)$.

        % Consider $P-C_{LM}(P)\cdot Q$. We have
        % \begin{equation*}
        %     LM(P-C_{LM}(P)\cdot Q) \prec LM(P)
        % \end{equation*}
        % and $P-C_{LM}(P)\cdot Q\in R^{S_n}$. By our assumption, this can be expressed through elementary symmetric polynomials, i.e., $P-C_{LM}(P)\cdot Q\in\Q[\sigma_1,\dots,\sigma_n]$. Thus, $P\in\Q[\sigma_1,\dots,\sigma_n]$.


        We will prove this theorem using the well-ordering principle (every set of natural numbers has a smallest element), which is equivalent to induction. Let's begin.\par
        Suppose for the sake of contradiction that there exists a symmetric polynomial that cannot be expressed via $\sigma_1,\dots,\sigma_n$. Given this counterexample, factor out as many terms as we want (successively reducing the degree) until it ceases to be a counterexample, thus yielding the counterexample of smallest degree. Similarly, get to the counterexample with smallest $LM$. Call this counterexample $P(x_1,\dots,x_n)$. Let
        \begin{equation*}
            P(x_1,\dots,x_n) = C_{LM}(P)\underbrace{x_1^{a_1}\cdots x_n^{a_n}}_{LM(P)}+\text{smaller monomials}
        \end{equation*}
        Since $P$ is symmetric and the term above is the lexicographically largest monomial, the Lemma implies that $a_1\geq\cdots\geq a_n$. We now construct a polynomial $Q$ out of the $\sigma_i$ such that $LM(P)=LM(Q)$. To begin, note that
        \begin{align*}
            LM(\sigma_1) &= x_1&
            LM(\sigma_2) &= x_1x_2&
            &\cdots&
            LM(\sigma_n) &= x_1\cdots x_n
        \end{align*}
        Now consider $\sigma_n^{a_n}$. This clearly divides $LM(P)$ since $a_n$ is minimal. Now multiply by $\sigma_{n-1}^{a_{n-1}-a_n}$. Continuing on, we get
        \begin{equation*}
            Q = \sigma_n^{a_n}\sigma_{n-1}^{a_{n-1}-a_n}\sigma_{n-2}^{a_{n-2}-a_{n-1}}\cdots\sigma_1^{a_1-a_2}
        \end{equation*}
        Now it follows that
        \begin{equation*}
            LM(P-C_{LM}(P)\cdot Q) \prec LM(P)
        \end{equation*}
        Since $C_{LM}(P)\in\Q$ and $Q\in\Q[x_1,\dots,x_n]^{S_n}$, it also follows that $P-C_{LM}(P)\cdot Q\in\Q[x_1,\dots,x_n]^{S_n}$. But then by the assumption that $P$ was the counterexample with smallest $LM$, we know that $P-C_{LM}(P)\cdot Q\in\Q[\sigma_1,\dots,\sigma_n]$. It follows that $P\in\Q[\sigma_1,\dots,\sigma_n]$, a contradiction.
    \end{proof}
    \item Note: This is an effective proof; we can write an algorithm to do this for us, and it's actually pretty fast and efficient.
    \item ?? (\emph{word in blackboard picture}) to show: $\sigma_1,\dots,\sigma_n$ are algebraically independent $P(\sigma_1,\dots,\sigma_n)=0$ implies that $P=0$.
    \begin{itemize}
        \item This will be a homework problem; hint, it's pretty easy.
    \end{itemize}
    \item Back to representation theory.
    \item \textbf{Antisymmetric} (polynomial): A polynomial $P(x_1,\dots,x_n)$ such that
    \begin{equation*}
        \sigma P=(-1)^\sigma P
    \end{equation*}
    \item Example.
    \begin{itemize}
        \item $n=2$: $x_1-x_2$.
        \item $n=3$: $(x_1-x_2)(x_1-x_3)(x_2-x_3)$.
    \end{itemize}
    \item These main examples are the \textbf{Vandermode determinant} from last time!
    \item \textbf{Vandermonde determinant}:
    \begin{equation*}
        \Delta(x_1,\dots,x_n)=\prod_{1\leq i<j\leq n}(x_j-x_i)
    \end{equation*}
    \item Exercise: $\Delta(x_1,\dots,x_n)$ is antisymmetric.
    \item One of the nicest definitions of sign comes from these determinants!
    \begin{equation*}
        (-1)^\sigma = \frac{\prod_{i<j}(x_{\sigma(i)}-x_{\sigma(j)})}{\prod_{i<j}(x_i-x_j)}
    \end{equation*}
    \item Theorem: If $P\in\Q[x_1,\dots,x_n]^\text{alt}$ (i.e., $P\in\Q[x_1,\dots,x_n]$ and $P$ is antisymmetric), then $P=P'\Delta(x_1,\dots,x_n)$ where $P'$ is symmetric (i.e., $P'\in\Q[x_1,\dots,x_n]^{S_n}$).
    \item Corollary: If $P$ is antisymmetric and $\deg(P)<n(n-1)/2$, then $P=0$.
    \begin{itemize}
        \item We'll use this many times, this fact that "antisymmetric polynomials have a smallest possible degree."
    \end{itemize}
    \item We now prove the Theorem.
    \begin{proof}
        Let $P$ be antisymmetric. Then $(12)P=-P$. It follows that $\eval{P(x_1,\dots,x_n)}_{x_1=x_2}=0$. Now, rewrite $P$ as a polynomial in one variable where all of the coefficients are polynomials in other variables. In particular, let
        \begin{equation*}
            P = P_d(x_1-x_2)^d+P_{d-1}(x_1-x_2)^{d-1}+\cdots+P_0
        \end{equation*}
        where each $P_i\in\Q[x_1,\dots,x_d]$. What is $d$?? (Less than $n$, I'm assuming, but any other constraints?) Plugging in $x_1=x_2$ once again, we get $0=P=P_0$. But this implies that $P_0=0$. Thus, $P$ is divisible by $x_1-x_2$. Similarly, for all $i<j$, $(x_i-x_j)\mid P$. But since the $x_i-x_j$ are irreducible polynomials, we have that $\prod_{i<j}(x_j-x_i)\mid P$. This is justified because we are in a unique factorization domain (how is this relevant??). Thus, we have that $P=P'\cdot\Delta(x_1,\dots,x_n)$. Lastly, it follows that $P'\in\Q[x_1,\dots,x_n]^{S_n}$ because under any sign $-1$ permutation, $\Delta(x_1,\dots,x_n)$ will flip signs and $P$ will still be equal, so $P'$ had better just stay itself under this permutation (i.e., be symmetric).
    \end{proof}
    \item Remark: Where does the name Vandermonde \emph{determinant} come from?
    \begin{itemize}
        \item We have that
        \begin{equation*}
            \Delta(x_1,\dots,x_n) =
            \begin{vmatrix}
                1 &  &  & 1\\
                x_1 &  &  & x_n\\
                \vdots &  &  & \vdots\\
                x_1^{n-1} &  &  & x_n^{n-1}\\
            \end{vmatrix}
        \end{equation*}
    \end{itemize}
    \item Final reminder before the final.
    \begin{itemize}
        \item Don't forget our awesome central construction!
        \item If $\lambda=(\lambda_1,\dots,\lambda_k)$ is a partition with $\lambda_1\geq\cdots\geq\lambda_k$, then we can draw a Young Diagram and construct an associated representation $V_\lambda\in\C[x_1,\dots,x_n]$.
        \item But what we do is $V_\lambda=\C[S_n]\Delta_\lambda$, where
        \begin{equation*}
            \Delta_{\lambda'} = \Delta(x_1,\dots,x_{\lambda_1'})\Delta(x_{\lambda_1'+1},\dots,x_{\lambda_1'+\lambda_2'})\cdots
        \end{equation*}
        \item Example: For $\lambda=(2,2,1)$, we have $V_{(2,2,1)}=\C[S_n](x_1-x_2)(x_1-x_3)(x_2-x_3)(x_4-x_5)$.
        \item Next time, we'll prove that $V_{(2,2,1)}$ is irreducible.
    \end{itemize}
    \item This Specht construction is in a tiny footnote of \textcite{bib:FultonHarris}, but that's about it!
\end{itemize}



\section{Midterm Review Sheet}
\begin{itemize}
    \item \marginnote{11/10:}The following definitions and results will be useful in solving the midterm problems.
    \item \textbf{Group representation}: A group homomorphism $\rho:G\to GL(V)$ for $G$ a finite group, $V$ a finite-dimensional vector space over some field $\F$ with basis $\{e_1,\dots,e_n\}$, and $GL(V)$ the set of isomorphic linear maps $L:V\to V$.
    \item \textbf{Morphism} (of $G$-representations): A map $f:V\to W$ such that\dots
    \begin{enumerate}
        \item $f$ is linear;
        \item For every $g\in G$, $\rho_W(g)\circ f=f\circ\rho_V(g)$.
        \begin{itemize}
            \item To remember this rule, draw out the commutative diagram!
        \end{itemize}
    \end{enumerate}
    \item Theorem (complete reducibility): Any finite-dimensional representation can be decomposed into a direct sum of irreducible representations via
    \begin{equation*}
        V = V_1^{n_1}\oplus\cdots\oplus V_k^{n_k}
    \end{equation*}
    \item Lemma (Schur's Lemma): Let $G$ be a finite group, let $V,W$ be irreducible representations over $\C$, and let $f\in\Hom_G(V,W)$. Then\dots
    \begin{enumerate}
        \item If $V\ncong W$, then $f=0$. If $V\cong W$, then $f$ is an isomorphism of $G$-representations.
        \item If $f:V\to V$, then $f(v)=\lambda v$.
    \end{enumerate}
    \item \textbf{Algebraic integer}: A number $x\in\C$ for which there exist $a_0,\dots,a_{n-1}\in\Z$ such that
    \begin{equation*}
        x^n+a_{n-1}x^{n-1}+\cdots+a_0 = 0
    \end{equation*}
    \item \textbf{Character} (of $\rho$): The function $\chi_\rho:G\to\C$ defined by
    \begin{equation*}
        \chi_\rho(g) = \tr(\rho(g))
    \end{equation*}
    \item \textbf{First orthogonality relation}: If $\chi_1,\chi_2$ are the characters of irreducible representations, then
    \begin{equation*}
        \sum_{g\in G}\chi_1(g)\overline{\chi_2(g)} =
        \begin{cases}
            0 & \chi_1\neq\chi_2\\
            |G| & \chi_1=\chi_2
        \end{cases}
    \end{equation*}
    \begin{itemize}
        \item Follows from the fact that the characters form an orthonormal set within the space of class functions, and the definition of the inner product on this space.
    \end{itemize}
    \item \textbf{Second orthogonality relation}: If $C_G(g)$ is the number of elements in the conjugacy class of $g$, then
    \begin{equation*}
        \sum_\chi\chi(g_1)\overline{\chi(g_2)} =
        \begin{cases}
            0 & g_1\nsim g_2\\
            \frac{|G|}{|C_G(g_1)|} & g_1\sim g_2
        \end{cases}
    \end{equation*}
    \item \textbf{Permutational representation}: The representation $\rho:S_n\to\C^n(=V_\text{perm})$ defined by
    \begin{equation*}
        \rho(\sigma):(x_1,\dots,x_n)\mapsto(x_{\sigma(1)},\dots,x_{\sigma(n)})
    \end{equation*}
    \begin{itemize}
        \item Character: Compute $\Fix(\sigma)$ for each type of $\sigma$.
    \end{itemize}
    \item \textbf{Class function}: A function that is constant on the conjugacy classes of $G$. Explicitly, for all $s,t\in G$,
    \begin{equation*}
        f(tst^{-1}) = f(s)
    \end{equation*}
    \item \textbf{Group algebra}: The complex vector space with basis $\{e_g\}$ corresponding to the elements of group $G$, plus the definition $e_g\cdot e_h=e_{gh}$.
    \item \textbf{Semisimple module}: A module $M$ that satisfies any of the following three conditions.
    \begin{enumerate}
        \item $M=\bigoplus_{i\in I}S_i$, where each $S_i$ is a simple module and $I$ is an indexing set.
        \item $M=\sum_{i\in I}S_i$.
        \item For all submodules $N\subset M$, there exists $N'$ such that $M=N\oplus N'$.
    \end{enumerate}
    \item Additional notes on semisimple modules.
    \begin{itemize}
        \item Simple module: A module that is nonzero and has no nonzero proper submodules.
    \end{itemize}
    \item \textbf{Division algebra}: An algebra $D$ such that for all nonzero $x\in D$, there exists a $y\in D$ such that $xy=1$.
    \item \textbf{Semisimple algebra}: An algebra for which every finite-dimensional $A$-module is semisimple.
    \item \textbf{Wedderburn-Artin theorem}: If $A$ is a finite-dimensional semisimple associative algebra, then
    \begin{equation*}
        A \cong M_{n_1}(D_1)\oplus\cdots\oplus M_{n_k}(D_k)
    \end{equation*}
    \item \textbf{Schur's Lemma} (over an arbitrary field): Let $A$ be a finite-dimensional algebra, and let $M_1,M_2$ be simple $A$-modules. Then\dots
    \begin{enumerate}
        \item If $f:M_1\to M_2$ is a nonzero morphism of $A$-modules, $f$ is isomorphic;
        \item If $M$ is simple, $\Hom_A(M,M)$ is a division algebra.
    \end{enumerate}
    \item \textbf{Center} (of $A$): The following set.
    \begin{equation*}
        Z(A) = \{a\in A\mid xa=ax\ \forall\ x\in A\}
    \end{equation*}
    \item \textbf{Jacobson radical}: The finite-dimensional $A$-algebra defined as follows.
    \begin{equation*}
        \Rad(A) = \{a\in A\mid aS=0\text{ for any simple module }S\}
    \end{equation*}
    \item Here's an outline of what to remember for the problems.
    \item Strategies for computing the following things from the character table of a group.
    \begin{enumerate}
        \item Tensor products.
        \begin{itemize}
            \item Multiply corresponding characters.
        \end{itemize}
        \item Wedge/symmetric squares.
        \begin{itemize}
            \item If $\chi$ is the character of a representation $\rho:G\to GL(V)$, then the characters $\chi_\sigma^2$ of the symmetric square $S^2V$ of $V$ and $\chi_\alpha^2$ of the alternating square $\Lambda^2V$ of $V$ are given by the following for each $s\in G$.
            \begin{align*}
                \chi_\sigma^2(s) &= \frac{1}{2}\left( \chi(s)^2+\chi(s^2) \right)&
                \chi_\alpha^2(s) &= \frac{1}{2}\left( \chi(s)^2-\chi(s^2) \right)
            \end{align*}
            \item Note that just like $V^{\otimes 2}=S^2V+\oplus\Lambda^2V$, we have $\chi^2=\chi_\sigma^2+\chi_\alpha^2$.
        \end{itemize}
        \item Decomposing permutational representations into irreducibles.
        \begin{itemize}
            \item If the representation of interest is $\chi_V$, we find the coefficients $n_i$ of its decomposition
            \begin{equation*}
                \chi_V = \sum n_i\chi_{V_i}
            \end{equation*}
            via the inner product
            \begin{equation*}
                n_i = \inp{\chi_V,\chi_{V_i}} = \frac{1}{|G|}\sum_{g\in G}\chi_V(g)\overline{\chi_{V_i}(g)}
            \end{equation*}
        \end{itemize}
        \item More.
    \end{enumerate}
    \item Strategies for computing the following things given a small group (e.g., the quaternion group).
    \begin{enumerate}
        \item Conjugacy classes.
        \begin{itemize}
            \item Take an element, conjugate it by everything, round up the products. Then move onto another elements.
        \end{itemize}
        \item Character table.
        \begin{itemize}
            \item Find the conjugacy classes and put them at the top of the table. This also tells us how many irreps we need to get to.
            \item Start with the trivial, alternating, and standard representations.
            \item Tensor products of representations with 1D representations (e.g., the alternating) are often linearly independent.
            \item We can recover the standard as the difference of the permutation and trivial.
            \item We can solve for representations as components of the regular representation via
            \begin{equation*}
                V_R = \bigoplus_{i=1}^kV_i^{\dim V_i}
            \end{equation*}
            \item We can calculate the degrees of remaining representations via the sums of the squares of the dimensionalities.
            \item We can fill in final representations with the orthogonality relations, \emph{especially} the second one.
        \end{itemize}
        \item Decomposing representations into a sum of isotypical components.
        \begin{itemize}
            \item Use the inner product/decomposition formula from above.
        \end{itemize}
        \item Diagonalizing an endomorphism.
        \begin{itemize}
            \item Start with its matrix $A$.
            \item Find the characteristic polynomial by computing $\det(A-\lambda I)$.
            \item Solve for the eigenvalues.
            \item Find, by inspection or by solving systems of equations, elements of the null space of $A-\lambda I$ for each $\lambda$. Beware eigenvalues with multiplicity greater than one!
        \end{itemize}
        \item More.
    \end{enumerate}
    \item Strategies for solving an abstract problem about characters.
    \begin{itemize}
        \item \emph{reread notes}
    \end{itemize}
    \item Strategies for solving an abstract problem about representations.
    \begin{itemize}
        \item \emph{reread notes}
    \end{itemize}
    \item Other misc. concepts that are probably good to remember (my own ideas).
    \item \textbf{Left $\bm{A}$-module}: A pair $(M,\rho)$ where $(M,+)$ is an abelian group and $\rho:A\to\End(M)$ is the ring homomorphism defined as follows, where $A$ is a ring: For all $a\in A$, $\rho(a):M\to M$ is given by $\rho(a)v=av$ for all $v\in M$ and satisfies the following constraints.
    \begin{enumerate}
        \item $\rho(a):M\to M$ is a group homomorphism on $(M,+)$.
        \item $\rho$ is a ring homomorphism.
        \begin{itemize}
            \item That is to say, $\rho(a+b)=\rho(a)+\rho(b)$, $\rho(ab)=\rho(a)\rho(b)$, and $\rho(1_A)=1_{\End(M)}$.
        \end{itemize}
    \end{enumerate}
    \item Lemma (Gauss's Lemma): If $f,g\in R[X]$ are both nonzero polynomials with coefficients in the ring $R$, then $c(fg)=c(f)c(g)$.
    \begin{itemize}
        \item Note that $c(f)$ denotes the \textbf{content} of $f$, which is the gcd of its coefficients.
        \item Use: If $p$ is reducible in a fraction field, then it's reducible in the native UFD.
    \end{itemize}
    \item $A$ is semisimple iff $\Rad(A)=0$.
    \item Formulas for the decomposition of the regular representation/misc. formulas from IChem.
    \begin{itemize}
        \item Sum of the squares of the dimensionalities (from the second orthogonality relation):
        \begin{equation*}
            |G| = \sum_{i=1}^k(\dim V_i)^2
        \end{equation*}
        \item Sum of the squares of an irrep's characters (from the first orthogonality relation):
        \begin{equation*}
            |G| = \sum_{g\in G}\chi(g)^2
        \end{equation*}
    \end{itemize}
\end{itemize}



\section{Midterm}
\begin{enumerate}
    \item \textbf{(30)} Here is the character table of the group $S_4$.
    \begin{center}
        \begin{tabular}{||cccccc||}
            \hline
            Representation & $(1)(2)(3)(4)$ & $(12)(34)$ & $(12)(3)(4)$ & $(1234)$ & $(123)(4)$\\
            \hline\hline
            $(4)$       & $1$ & $1$  & $1$  & $1$  & $1$\\ \hline
            $(1,1,1,1)$ & $1$ & $1$  & $-1$ & $-1$ & $1$\\ \hline
            $(2,2)$     & $2$ & $2$  & $0$  & $0$  & ?  \\ \hline
            $(3,1)$     & $3$ & ?    & $1$  & $-1$ & $0$\\ \hline
            $(2,1,1)$   & $3$ & $-1$ & $-1$ & $1$  & $0$\\ \hline
        \end{tabular}
    \end{center}
    \begin{enumerate}
        \item State two orthogonality relations for characters of a general group $G$. Apply them to fill in holes in the table above.
        \item Compute the character of $S^2(2,2)$ and decompose it into irreducibles.
        \item Compute the character of $(3,1)\otimes(2,2)$ and decompose it into irreducibles.
    \end{enumerate}
    \item \textbf{(40)} Consider the group $G$ of symmetries of a square (it has size 8).
    \begin{enumerate}
        \item Find the conjugacy classes of $G$.
        \item The action of $G$ on the plane (by symmetries of a square) defines a two-dimensional complex representation $V$ of $G$. Find the character of $V$. Prove that $V$ is irreducible.
        \item Compute the character table of $G$.
        \item Consider the action of $G$ on the set of functions on edges of teh square. This defines a four-dimensional representation of $G$. Find its characters and decompose it into isotypical components.
    \end{enumerate}
    \item \textbf{(15)} Suppose that for a finite group $G$ all irreducible representations are one-dimensional. Prove that $G$ is abelian.
    \item \textbf{(15)} State Schur's lemma for complex representations of a finite group. Assume that $V,W$ are two distinct complex-dimensional irreducible representations of a finite group $G$. Find the dimension of the space $\Hom_G(V\oplus W,V\oplus W)$.
\end{enumerate}




\end{document}